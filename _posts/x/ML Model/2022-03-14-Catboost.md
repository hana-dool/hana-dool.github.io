---
title:  "Catboost"
excerpt: ""
tags:
  - ML_Model
last_modified_at: 2022-03-14

toc: true
toc_label: "Table Of Contents"
toc_icon: "cog"
toc_sticky: true

use_math: true
typora-root-url: ../../../../hana-dool.github.io
---

 Catboost 에 대해서 알아보도록 하자.
{: .notice--warning}

# [Idea of Catboost](#link){: .btn .btn--primary}{: .align-center}

> ## Backgrounds : Gradient Boost

- Background in brief
  - $\checkmark$ Assume we observe a dataset of examples $\mathcal{D}=\left\{\left(\mathbf{x}_{k}, y_{k}\right)\right\}_{k=1, \ldots, n}$
  - where $\mathbf{x}_{k}=\left(x_{k}^{1}, \ldots, x_{k}^{m}\right)$ is a random vector of $\mathrm{m}$ features and $y_{k} \in \mathbb{R}$ is a target
  - $\checkmark$ Gradient boosting builds iteratively a **sequence of approximations** $F^{t}: \mathbb{R}^{m} \rightarrow \mathbb{R}$ in a greedy fashion
  - 즉 어떤 t 번째의 부스팅 모형은 t-1 번쨰의 부스팅 모형 + 현재시점에서 찾은 모형($h^t$) * 가중치 모형이 됩니다.
  -  $F^{t}: F^{t-1}+\alpha h^{t}$ (alpha is a step size and $\mathrm{h}$ is a base predictor)
- 이떄 현재 시점 모델 $h^{t}$ 은 chosen from a family of functions $\mathrm{H}$ in order to minimize the expected loss 하도록 선택됩니다.
$$
h^{t}=\arg \min _{h \in H} \mathcal{L}\left(F^{t-1}+h\right)=\arg \min _{h \in H} \mathbb{E} L\left(y, F^{t-1}(\mathbf{x})+h(\mathbf{x})\right)
$$
- 즉 위처럼 , Loss 함수 ($L$) 에 대해서, 누정된 모델 ($F^{t-1}$) 에 대해서 , h 로 보정해주었을떄 loss 가 최소화 하는 모델이 $h^t$ 가 됩니다.
- The gradient step $h^{t}$ is chosen in such a way that $h^{t}(\mathbf{x})$ approximates $-g^{t}(\mathbf{x}, y)$, where
$$
g^{t}(\mathbf{x}, y):=\left.\frac{\partial L(y, s)}{\partial s}\right|_{s=F^{t-1}(\mathbf{x})}
$$
- 즉 최소화 하기 위해서, 추정되는 $h^t$ 의 방향은, Loss 를 가장 효과적으로 minimize 하는 $-g(\mathbf{x},y)$ 방향이 되게 됩니다.
- 또한 이러한 $h^t$ 를 찾기 위해서는 대게 Least Squares approximation 방법을 사용하여 아래처럼 계산되곤 합니다.

$$h^{t}=\arg \min _{h \in H} \mathbb{E}\left(-g^{t}(\mathbf{x}, y)-h(\mathbf{x})\right)^{2}$$

> ## Problem of Gradient Boosting

- Statistical Issue

$$
\arg \min _{h \in H} \mathbb{E}\left(-g^{t}(\mathbf{x}, y)-h(\mathbf{x})\right)^{2} \approx \quad \arg \min _{h \in H} \frac{1}{n} \sum_{k=1}^{n}\left(-g^{t}\left(\mathbf{x}_{k}, y_{k}\right)-h\left(\mathbf{x}_{k}\right)\right)^{2}
$$

$$
\text { Training Dataset: } \mathcal{D}=\left(\mathbf{x}_{k}, y_{k}\right)_{k=1, \ldots, n}
$$

$$
\text { where } \mathbf{x}_{k}=\left(x_{k}^{1}, \ldots, x_{k}^{m}\right), \quad y_{k} \in \mathbb{R}
$$

- 우리는 위 그림에서 gradient 를 계산하기 위해서는, 원칙적으로는 모든 데이터셋에 대해서 Expectation 이 최소화 되게 하기 위한 h 를 구하는것이 원칙입니다. (좌측 함수)
- 하지만 이게 불가능하므로, 우측 값처럼 "Train dataset" 을 이용하여 근사값을 구합니다. 

> issue 1 : 학습데이터 모형과, Test 데이터 조건부 모형이 다르므로 데이터 정합성이 틀어지게 됨

- 학습데이터에 대한 조건부 확률과, Test 데이터에 대한 조건부 확률이 다르다는게 첫번쨰 이슈입니다.

$$
F^{t-1}\left(\mathbf{x}_{k}\right) \mid \mathbf{x}_{k} \not=F^{t-1}(\mathbf{x}) \mid \mathbf{x}
$$

- 실제 데이터에서는 expectation 이 유한한 데이터에서는 불가능합니다.
  - 누적된 boosting 의 
- 그래서 학습데이터에 대한 조건부 함수와, 누적함수에 대한 조건부 확 이용하여 위처럼 근사!

![jpg](/assets/images/Stat/161_1.jpg){: .align-center}

- 즉 위와 같이 Training example 에 대한 Conditional Distribution 과, Test Example 에 대한 Conditional Distribution 이 다르다는것이 문제가 됩니다.

> Target Leakage

- Target 변수가 어떠한 Feature 를 계산하는데에 사용된다는 의미 
- Gradient Boosting
  - $\checkmark$ Statistical Issue 2:Target Leakage
    - Target Statistic (TS): Replace the categorical feature with it mean target value in the training dataset
    - (Problem) Target value of an instance is used to compute its feature value (target information is leaked)

![jpg](/assets/images/Stat/161_2.jpg){: .align-center}

- 많은 머신러닝 계열에서, Target Statistic 을 이용해서, categorical 변수를 numerial 변수로 바꾸게 됩니다.
- 주요 하는것은 mean - target value 로 쓰게 됨
  -  위와 같이 $x^i$ 는 카테고리 변수라고 합시다. 

| 카테고리 | y target 1 비율 | Transform 값 |
| -------- | --------------- | ------------ |
| A        | 1/2 = 0.5       | 0.5          |
| B        | 2/3 = 0.67      | 0.67         |
| C        | 4/5 = 0.9       | 0.9          |

- 위처럼 카테고리의 변환을 할때에 정답인 y 가 feature value 를 계산하는데에 사용되고 있다는것입니다..!
  - 이는 정답정보가 Feature Value 변환시에 사용하고 있다는것이므로, 어떻게 보면 Cheating 과 같습니다.

> ## 해결책

- Catboost 는 두가지의 이슈에 대해서 다음과 같이 2가지로 해결책을 내놓습니다.
  - Target Leakage $\to$ Ordered Target Statistics 
  - Prediction Shift $\to$ Ordered Boosting

> ## Ordered Target Statistics 

- Ordered TS 는 Target Leakage 를 방지하기 위함입니다.
  - 즉 특정한 Feature Value 를 계산할때 y 값을 쓰지 않고 Categorical value를 어떻게 변환할지? 에 대한 해결입니다.

> one hot vector 는? 

![jpg](/assets/images/Stat/161_3.jpg){: .align-center}

- 위와 같이 one hot vector 로 변환하는 경우에는 category 의 수만큼 변수가 추가되게 됩니다.. ㅜㅜ

> Target Statistics 

- 두번쨰로 대표적인 방법은, 카테고리를 Grouping 한 뒤에, 카테고리컬 변수로 바꾸는 것입니다.

![jpg](/assets/images/Stat/161_4.jpg){: .align-center}

- 각각을  

- Categorical features in boosted tree
  - $\checkmark$ Another popular method: to group categories by target statistics
    - an estimate expected target value in each category
    - Greedy TS without smoothing $\hat{x}_{k}^{i} \approx \mathbb{E}\left(y \mid x^{i}=x_{k}^{i}\right)$
    - $\mathrm{i}$ is a categorical feature while $k$ is training example index
- Greedy Target Statistic 관점에서 보면, 학습데이터에 존재하는 객체들이 가지는 y 값의 평균입니다.

> Ordered TS 


$$
\begin{array}{cccc} 
& y=1 & y=0 & T S \\
A & 10 & 10 & 0.5 \\
B & 40 & 10 & 0.8 \\
C & 10 & 40 & 0.2 \\
D & 25 & 25 & 0.5 \\
E & 1 & 0 & 1
\end{array}
$$

- 위와 같이 스무싱을 하지 않은 target statistic 의 경우 (TS) E 처럼 간혹가다 나오는 Noise 라 볼 수 있는 카테고리 변수에 대해 그냥 Expectation 값을 사용하게 되면, 다른 값에 비해 극단적인 값이 나오게 됩니다.
- 그래서 a 와 p 라는 값을 이용하게 됩니다.

- Categorical features in boosted tree
- $\checkmark$ Another popular method: to group categories by target statistics (TS)
  - Greedy TS with smoothing
$$
\hat{x}_{k}^{i}=\frac{\sum_{j=1}^{n} \mathbb{1}_{\left\{x_{j}^{i}=x_{k}^{i}\right\}} \cdot y_{j}+a p}{\sum_{j=1}^{n} \mathbb{1}_{\left\{x_{j}^{i}=x_{k}^{i}\right\}}+a}
$$
- $a>0$ is a parameter 
- A common setting for $p$ is the average target value in the dataset
  - 전체 데이터에 대한 target value
- 위와 같이 계산하게 되면 이전에 E 와 같은 경우에 대해서 좀 더 transformation 값이 좋아집니다.
- Used to remove the negative effect of low-frequency noisy categories

> Example

![jpg](/assets/images/Stat/161_5.jpg){: .align-center}

- 위와 같은 테이블에서 각각의 Catetgory 에 들어갈 값을 계산한다고 합시다.

> A 계산 

$$
\hat{x}_{k}^{A}=\frac{\sum_{j=1}^{n} \mathbb{1}_{\left\{x_{j}^{A}=x_{k}^{A}\right\}} \cdot y_{j}+a p}{\sum_{j=1}^{n} \mathbb{1}_{\left\{x_{j}^{A}=x_{k}^{A}\right\}}+a}
$$

- a = 0.1 (우리가 정하는 파라미터)
- p = 7/10 = 0.7 (training 데이터셋으로부터 계산됩니다.)
- $$\sum_{j=1}^{n} \mathbb{1}^{\mathbb{1}}\left\{x_{j}^{A}=x_{k}^{A}\right\}^{\cdot} y_{j}  \to$$  x'=A 인 값들 중에서 , y=값의 합 $\to$  1
- $${\sum_{j=1}^{n} \mathbb{1}_{\left\{x_{j}^{A}=x_{k}^{A}\right\}}} \to$$ x' = A 인 데이터의 총 수 $\to$ 2

$$
=\frac{1+0.1 \times 0.7}{2+0.1}=0.5095
$$

> B 계산

![jpg](/assets/images/Stat/161_6.jpg){: .align-center}

- 위와 같이 B 의 계산도 동일하게 이루어집니다.

![jpg](/assets/images/Stat/161_7.jpg){: .align-center}

- 최종적으로는 위와 같이 변환됩니다.

- Target leakage
$\checkmark$ feature $\hat{x}_{k}^{i}$ is computed using $y_{k}$, the target of $\mathbf{x}_{k}$
$\checkmark$ leads to a conditional shift: the distribution of $\hat{x}^{i} \mid y$ differs for training and test examples

$$
\hat{x}_{k}^{i}=\frac{\sum_{j=1}^{n} \mathbb{1}_{\left\{x_{j}^{i}=x_{k}^{i}\right\}} \cdot y_{j}+a p}{\sum_{j=1}^{n} \mathbb{1}_{\left\{x_{j}^{i}=x_{k}^{i}\right\}}+a}
$$

- target leakage 에 대해서 다시 이야기하면, 카테고리를 바꾸는 과정에서 해당하는 객체의 해당정보인 $y_k$  가사용되는게 문제였습니다.
- 그러므로 임해서 Conditional Shift 가 일어나는게 문제
  - 즉 각각의  $\hat{x}^{i}$ (변환되는 카테고리 피쳐 값) 이 Train Data 와 Train Data 에 대해서 달라진다는게 문제였음! 

> Train Dataset

- Train 데이터를 $$X^{Train}_{\text {old }}$$ 라 합시다. 
- 이때 i 번째 데이터를 $X^i_{Train}$ 라고 하고, 이를 Target Statistic 으로 변환하려 한다고 합시다.
- 이떄 이를 변환하기 위해서는 , Training Data 를 이용해서 적합된 TS - Transfomration 을 이용하게 됩니다. 
- 즉 Training Data 인 $X_{old}^{Test}$ 를 변환하기 위해서는 $y_{train}$ 를 사용하게 됩니다.

> Test Dataset

- Test 데이터를 $$X^{Test}_{\text {new }}$$ 라 합시다. 
- 이때 i 번째 데이터를 $X^i_{new}$ 라고 하고, 이를 Target Statistic 으로 변환하려 한다고 합시다.
- 이떄 이를 변환하기 위해서는 , Training Data 를 이용해서 적합된 TS - Transfomration 을 이용하게 됩니다. (Training data 에 해당하는 X 값)
- 즉 실제로는 test data 의 label 인 $y_{test} $  는 사용하지 않는다는 것이죠.

> problem

- 즉 문제가 되는것은, 현재 example 에 대해서 예측을 할 떄에는 , y 타겟을 사용하지 말아야한다는것입니다. 
- 그래야 Prediction Shift (Conditional Shift) 가 일어나지 않는다는 것입니다! 

> ## Example 

- Target leakage
  - $\checkmark$ feature $\hat{x}_{k}^{i}$ is computed using $y_{k}$, the target of $\mathbf{x}_{k}
  - $\checkmark$ leads to a conditional shift: the distribution of $\hat{x}^{i} \mid y$ differs for training and test examples
- Assume that $\mathrm{i}^{\text {th }}$ feature is categorical, all its values are unique, $P\left(y=1 \mid x^{i}\right)=0.5, x^{i} \in\{A, B, C, D, E, F, \ldots\}$

![jpg](/assets/images/Stat/161_8.jpg){: .align-center}

- 위와 같이 6개의 $x^i$ 카테고리는 모두 유니크하하다고 합시다.
-  y = 1 의 target 을 가지고 있는 $I_1,I_2,I_3$ 데이터에 대해서는 TS 가 $\frac{1+ap}{1+a}$ 로 변환됩니다. 
-  y = 0 의 target 을 가지고 있는 $I_1,I_2,I_3$ 데이터에 대해서는 TS 가 $\frac{0+ap}{1+a}$ 로 분환됩니다.
- 이는 , 오른쪽의 빨간 선처럼 Split Criterion 을 $x^{i}=\frac{0.5+a p}{1+a}$ 로 설정하게 되면 학습과정에서는 완벽하게 1과 0을 구별할 수 있게 된다는것을 의미합니다.

![jpg](/assets/images/Stat/161_9.jpg){: .align-center}

- 그런데 위처럼, Test Set 에 대해서 Train Data 에서 한번도 나오지 않았던 Class 인 G , H , I , J 가 나오게 되면, 이때 $\sum_{j=1}^{n} \mathbb{1}_{\left\{x_{j}^{i}=x_{k}^{i}\right\}}$ 가 0 이 나오므로 $\hat{x}_{k}^{i}=\frac{\sum_{j=1}^{n} \mathbb{1}_{\left\{x_{j}^{i}=x_{k}^{i}\right\} \cdot y_{j}+a p}}{\sum_{j=1}^{n} \mathbb{1}_{\left\{x_{j}^{i}=x_{k}^{i}\right\}}+a}= \frac{ap}{a} =p$ 처럼 모두 p 로 코딩되게 됩니다.
- 즉 이러한 Feature Transformation 은 target 을 분류하기 위한 아무런 정보량이 없게 됩니다.

> ## Target Statistics 가 가져야할 바람직한 Property

$\checkmark$ Property I:
$$
\mathbb{E}\left(\hat{x}^{i} \mid y=v\right)=\mathbb{E}\left(\hat{x}_{k}^{i} \mid y_{k}=v\right)
$$
- where $\left(\mathbf{x}_{k}, y_{k}\right)$ is the $k-$ th training example
- 즉, 학습데이터와 테스트 데이터에 대해서 Expectation 이 같아야 함을 의미합니다.

$\checkmark$ Property 2 :

- Effective usage of all training data for calculating TS features and for learning a model
- 즉 모든 데이터셋을 모두 효율적으로 이용해야 한가는 것입니다.

> Way to avoid conditional shift

- 이러한 Conditional shift 를 피하기 위한 몇가지 방법이 존재합니다.

$\checkmark$ General idea: compute the TS for $\mathbf{x}_{k}$ on a subset of examples $\mathcal{D}_{k} \subset \mathcal{D} \backslash\left\{\mathbf{x}_{k}\right\}$ excluding $\mathbf{x}_{k}$
$$
\hat{x}_{k}^{i}=\frac{\sum_{\mathbf{x}_{j} \in \mathcal{D}_{k}} \mathbb{1}_{\left\{x_{j}^{i}=x_{k}^{i}\right\}} \cdot y_{j}+a p}{\sum_{\mathbf{x}_{j} \in \mathcal{D}_{k}} \mathbb{1}_{\left\{x_{j}^{i}=x_{k}^{i}\right\}}+a}
$$

- 즉 $x_k$ 의 TS 를 계산할때, $y_k$ 의 정보를 이용지 않게 되므로, 이는 치팅이 아니라는 것이죠! 
- 그래서 이를 구현하기 위한 방법론이 몇가지 존재합니다.

$\checkmark$ Holdout TS
- 데이터셋을 두개의 파트로 나눕니다. $\mathcal{D}=\hat{\mathcal{D}}_{0} \cup \hat{\mathcal{D}}_{1}$
  - Use the former ($\hat{D_0}$)  to compute the TS
  - Use the latter ($\hat{D_2}$)for training
- Violates the Property 2 (모든 데이터를 써서 TS 를 계싼하지 않기 떄문입니다.)

$\checkmark$ Leave-one-out TS
- 학습 데이터에 대해서는 Take $\mathcal{D}_{k}=\mathcal{D} \backslash \mathbf{x}_{k}$ 를 이용해서 $x_k$ 를 변환합니다.
- 그 다음에 Test Dataset 을 변환할떄에는 Take $\mathcal{D}_{k}=\mathcal{D}$ 처럼 모든 데이터셋을 이용하는 방법입니다.

![jpg](/assets/images/Stat/161_10.jpg){: .align-center}

- 위처럼 $\hat{x}_{k}^{i}=\frac{\sum_{\mathbf{x}_{j} \in \mathcal{D}_{k}} \mathbb{1}_{\left\{x_{j}^{i}=x_{k}^{i}\right\}} \cdot y_{j}+a p}{\sum_{\mathbf{x}_{j} \in \mathcal{D}_{k}} \mathbb{1}_{\left\{x_{j}^{i}=x_{k}^{i}\right\}}+a}$ 를 계산해보면, 위와 같이 변환되게 됩니다
- $A_i$ 에 대한 변환은 위처럼 때 $\frac{2.5+a p}{4+a}$ 를 cutoff 로 설정하게 되면 완벽하게 y=1, y=0 을 분리할 수 있게됩니다. ㅇ
  - 즉 이 변수가 매우매우 효과가 있어보이죠.
  - 하지만 피쳐 i ($X_i$) 는  모두 A 라는 카테고리를 가집니다. 즉 쓰레기 피쳐라는 것이죠.
- Test Data 는 역시나 모든 i 피쳐는 $x_i = A $  라는 값이 나오게 되었고, $\frac{3+a p}{5+a}$ 로 코딩되었습니다.
  -  $\frac{2.5+a p}{4+a}$  라는 cutoff 는 아무 의미없게 된 것이죠.

> ## How To? 

- Ways to avoid conditional shift
  - $\checkmark$ Ordered TS: introduce an artificial time 
  - 즉 가상의 시간 개념을 차용하여 random 하게 permutation 을 시행하였습니다.
- a random permutation $\sigma$ of the training examples
  - 이때 random permutation 을 한번만 하는게 아니라 hyperparameter 로서 여러번 진행합니다.
  - 학습 진행시 / Tree 를 만들때마다 permutation 을 한번 더 시행하게 됩니다.
$$
\mathcal{D}_{k}=\left\{\mathbf{x}_{j}: \sigma(j)<\sigma(k)\right\}
$$
- 위 식을 보면, k번째 데이터의 Test Statistics 을 계산하기 위해서, k번쨰 "이전" 의 데이터만을 사용하여서 TS 를 계산하게 됩니다.
  - 이때 permutation 을 하지 않으면 $I_1$ 변수는 엄청 많이 사용되고, $I_n$ 변수는 매우 조금 사용될 것입니다.
  - 즉 이러한 불균형을 해소하기 위해서 permutation 을 계속 진행하는 것입니다.
- $a=0.1$ (parameter), $p=0$ (computed from the training dataset)
- 아래 데이터는 permutation 후에 ordered 되었다고 하겠습니다.
  - $I$

![jpg](/assets/images/Stat/161_11.jpg){: .align-center}

> $I_1$

$$
\begin{aligned}
\hat{x}_{k}^{i} &=\frac{\sum_{\mathbf{x}_{j} \in \mathcal{D}_{k}} \mathbb{1}_{\left\{x_{j}^{i}=x_{k}^{i}\right\}} \cdot y_{j}+a p}{\sum_{\mathbf{x}_{j} \in \mathcal{D}_{k}} \mathbb{1}_{\left\{x_{j}^{i}=x_{k}^{i}\right\}}+a} \\
&=\frac{0+0.1 \times 0}{0+0.1}=0
\end{aligned}
$$

- 먼저 발생한 데이터가 없으므로, 0 값을 넣었음 . 전체 평균(p) 도 0이므로 결국 값은 0

> $I_2$

$$
\begin{aligned}
\hat{x}_{k}^{i} &=\frac{\sum_{\mathbf{x}_{j} \in \mathcal{D}_{k}} \mathbb{1}_{\left\{x_{j}^{i}=x_{k}^{i}\right\}} \cdot y_{j}+a p}{\sum_{\mathbf{x}_{j} \in \mathcal{D}_{k}} \mathbb{1}_{\left\{x_{j}^{i}=x_{k}^{i}\right\}}+a} \\
&=\frac{0+0.1 \times 1.0}{0+0.1}=1.0
\end{aligned}
$$

- I_2 보다 먼저 등장한 B 가 없으므로, $$\sum_{\mathbf{x}_{j} \in \mathcal{D}_{k}}\left\{x_{j}^{i}=x_{k}^{i}\right\}=0$$ 이 됨. 
- 다만 이전 ($I_1=1$) 이므로, p = 1/1 = 1 이 됩니다. 

> $I_3$

$$
\begin{aligned}
\hat{x}_{k}^{i} &=\frac{\sum_{\mathbf{x}_{j} \in \mathcal{D}_{k}} \mathbb{1}_{\left\{x_{j}^{i}=x_{k}^{i}\right\}} \cdot y_{j}+a p}{\sum_{\mathbf{x}_{j} \in \mathcal{D}_{k}} \mathbb{1}_{\left\{x_{j}^{i}=x_{k}^{i}\right\}}+a} \\
&=\frac{0+0.1 \times 1}{0+0.1}=1.0
\end{aligned}
$$

> $I_4$

$$
\begin{aligned}
\hat{x}_{k}^{i} &=\frac{\sum_{\mathbf{x}_{j} \in \mathcal{D}_{k}} \mathbb{1}_{\left\{x_{j}^{i}=x_{k}^{i}\right\}} \cdot y_{j}+a p}{\sum_{\mathbf{x}_{j} \in \mathcal{D}_{k}} \mathbb{1}_{\left\{x_{j}^{i}=x_{k}^{i}\right\}}+a} \\
&=\frac{1+0.1 \times 1.0}{1+0.1}=1.0
\end{aligned}
$$

> $I_6$

$$
\begin{aligned}
\hat{x}_{k}^{i} &=\frac{\sum_{\mathbf{x}_{j} \in \mathcal{D}_{k}} \mathbb{1}_{\left\{x_{j}^{i}=x_{k}^{i}\right\}} \cdot y_{j}+a p}{\sum_{\mathbf{x}_{j} \in \mathcal{D}_{k}} \mathbb{1}_{\left\{x_{j}^{i}=x_{k}^{i}\right\}}+a} \\
&=\frac{1+0.1 \times 0.75}{1+0.1}=0.977
\end{aligned}
$$

..............

![jpg](/assets/images/Stat/161_12.jpg){: .align-center}

> ## Check Assumption

- ordered TS 는 두가지 assumption 을 만족합니다.
  - k 번째 객체의 feature value 를 계산할때에 $y_k$ 를 사용하지 않는다. 
  - 되도록이면 모든 데이터를 이용한다. 

# [Prediction Shift](#link){: .btn .btn--primary}{: .align-center}

> ## Problem

$$
h^{t}=\arg \min _{h \in H} \mathbb{E}\left(-g^{t}(\mathbf{x}, y)-h(\mathbf{x})\right)^{2}
$$
- 이전의 문제를 다시 확인하자면, 위와 같이 Expectation 을 통해서 $h^t$ 를 추정하게 됩니다.
- 하지만 이러한 Expectation 은 Unknown 이기 때문에 샘플을 이용해서 아래와 같이 추정을 하게 됩니다.

$\checkmark$ The expectation is unknown and is usually approximated using the same dataset $\mathcal{D}$
$$
h^{t}=\arg \min _{h \in H} \frac{1}{n} \sum_{k=1}^{n}\left(-g^{t}(\mathbf{x}, y)-h(\mathbf{x})\right)^{2}
$$
- 하지만 Test Example 에서의 gradient 와 Train 에서의 gradient 가 다르기때문에 bias 되어 있을 것입니다.
- The conditional distribution of the gradient $g^{t}\left(\mathbf{x}_{k}, y_{k}\right) \mid \mathbf{x}_{k}$ is shifted from that distribution on a test example $g^{t}(\mathbf{x}, y) \mid \mathbf{x}$
- In turn, base predictor $h^{t}$ is biased from the solution
- Finally it affects the generalization ability of the trained model $F^{t}$
  - $F^{t}=F^{t-1}+\alpha h^{t}$ 로 표기되는데, $h^t$ 가 bias 되어있으면 자연스럽게 $F^{t-1}$ 도 bias 될 것이기 떄문입니다.
- $\checkmark$ When we learn a model with I trees, we need to have $F^{I-1}$ trained without the example $\mathbf{x}_{k}$ to make the residual $r^{I-1}\left(\mathbf{x}_{k}, y_{k}\right)$ unshifted
  - 즉 tree 를 만들때에는 $F^{I-1}$ 까지의 모델은 , $x_k$ 라는 example 을 사용하면 안된다는 이야기입니다.
  - 학습했을때 필요했던 객체들의 y 값을 계산하면 안된다는것과 비슷한 논지입니다.

> ## Ordered Boosting

- Random Permutation 

