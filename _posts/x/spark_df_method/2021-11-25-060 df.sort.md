---
title:  "df.sort"
excerpt: "데이터 정렬하기"
tags:
  - Spark_Function
last_modified_at: 2021-11-26

toc: true
toc_label: "Table Of Contents"
toc_icon: "cog"
toc_sticky: true

use_math: true
---

데이터타입 바꾸기
{: .notice--warning}

# [df.union](#link){: .btn .btn--primary}{: .align-center}

> ## 공식문서

> pyspark.sql.DataFrame.randomSplit(weights, seed=None)

- Randomly splits this [`DataFrame`](https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.html#pyspark.sql.DataFrame) with the provided weights.

> parameter

- Parameters: weights : list
  - list of doubles as weights with which to split the DataFrame. Weights will be
  - normalized if they don't sum up to $1.0$.
- seed : int, optional
  - The seed for sampling.

> ## 설명

- sort 와 orderBy 메서드를 활용하여 Dataframe 의 값들을 정렬할 수 있습니다.
  - 이 두 메서드는 완전히 같은 방식으로 동작합니다.

- 컬럼표현식 / 문자열을 사용할 수 있고, 다수의 컬럼을 지정할 수 있습니다. .
- 기본적인 동적 방식은 오름차순 정렬입니다.


> Example

```python
iris_df.sort('sepal_length').show(5)
#+------------+-----------+------------+-----------+-------+
#|sepal_length|sepal_width|petal_length|petal_width|variety|
#+------------+-----------+------------+-----------+-------+
#|         4.3|        3.0|         1.1|        0.1| Setosa|
#|         4.4|        3.2|         1.3|        0.2| Setosa|
#|         4.4|        3.0|         1.3|        0.2| Setosa|
#|         4.4|        2.9|         1.4|        0.2| Setosa|
#|         4.5|        2.3|         1.3|        0.3| Setosa|
#+------------+-----------+------------+-----------+-------+
```

- 위는 `sepal_length` 를 오름차순으로 정렬한것을 보여주고 있습니다.

> ## Example : 여러 column 정렬

- 여러 column 을 정렬하고자 하자면 아래와 같이 여러개를 써주면 됩니다.

```python
iris_df.sort('sepal_length','sepal_width').show(5)
#+------------+-----------+------------+-----------+-------+
#|sepal_length|sepal_width|petal_length|petal_width|variety|
#+------------+-----------+------------+-----------+-------+
#|         4.3|        3.0|         1.1|        0.1| Setosa|
#|         4.4|        2.9|         1.4|        0.2| Setosa|
#|         4.4|        3.0|         1.3|        0.2| Setosa|
#|         4.4|        3.2|         1.3|        0.2| Setosa|
#|         4.5|        2.3|         1.3|        0.3| Setosa|
#+------------+-----------+------------+-----------+-------+
```

> ## Example : expr desc 이 작동하지 않음

```python
iris_df.sort(expr("sepal_length desc")).show(2)
#+------------+-----------+------------+-----------+-------+
#|sepal_length|sepal_width|petal_length|petal_width|variety|
#+------------+-----------+------------+-----------+-------+
#|         4.3|        3.0|         1.1|        0.1| Setosa|
#|         4.4|        3.2|         1.3|        0.2| Setosa|
#+------------+-----------+------------+-----------+-------+
```

- 아니? 위와 같이 expr 을 이용해도, sort 가 되지 않는것을 볼 수 있습니다.
- 이는 바로 desc 를 단지 '별칭' 으로만 알아들어서 그렇습니다.

```python
expr("sepal_length desc")
# Column<'sepal_length AS `desc`'>
```

- 위를 보면 expr 을 적용해도 단지 별칭으로만 받아들여서, column 이 desc 라는 별칭으로 바뀌었다는것을 알 수 있죠.
  - 즉..  이러한 경우가 있어서 (expr 이라는 모호성? 때문에) 되도록이면 이러한 ordering 작업에는 expr 을 자제하는게 좋아보입니다.

> ## Example : 내림차순

```python
iris_df.orderBy(col("sepal_length").desc()).show(3)
#+------------+-----------+------------+-----------+---------+
#|sepal_length|sepal_width|petal_length|petal_width|  variety|
#+------------+-----------+------------+-----------+---------+
#|         7.9|        3.8|         6.4|        2.0|Virginica|
#|         7.7|        3.8|         6.7|        2.2|Virginica|
#|         7.7|        2.8|         6.7|        2.0|Virginica|
#+------------+-----------+------------+-----------+---------+
```

- 위처럼 sepal_lengh 에 대해서 내림차순을 적용할 수 있습니다.


---

**Reference**

- 스파크 완벽 가이드
- 스파크 공식 가이드북



