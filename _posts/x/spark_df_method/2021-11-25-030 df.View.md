---
title:  "df.createOrReplaceTempView"
excerpt: "뷰를 만들어서 SQL 쿼리를 실행시키기"
tags:
  - Spark_Function
last_modified_at: 2021-11-26

toc: true
toc_label: "Table Of Contents"
toc_icon: "cog"
toc_sticky: true

use_math: true
---

SQL 을 적용하기 위해서 뷰를 만드는것을 같이 공부해봅시다.
{: .notice--warning}

# [createOrReplaceTempView](#link){: .btn .btn--primary}{: .align-center}

> ## Note

> pyspark.sql.DataFrame.createOrReplaceTempView(name)

- Creates or replaces a local temporary view with this DataFrame.

> Note

- 우리는 스파크 내에서 SQL 쿼리를 실행하고 싶을 것입니다.
- 이럴때에 우리는 프로그램 내에서 SQL 쿼리를 실행하기 위하여 뷰를 만들어 낼 수 있습니다.
  - 뷰를 생성하면 뷰 정의가 시스템 내에 저장되었다가 SQL 내에서 뷰 이름을 사용하면 실행 시간에 뷰 정의가 대체되어 수행됩니다.

> ## sql 임시 뷰 만들기

-  `스파크데이터프레임.createOrReplaceTempView("객체명")` 메소드를 사용하면 데이터프레임에 SQL을 적용시킬 수 있는 객체를 별도로 만들게 됩니다.
- 그 이후에는 spark.sql()` 메쏘드를 사용해서 SQL 문을 던져 원하는 결과를 얻을 수 있습니다.

```python
# 스파크 데이터를 만들기
iris_df = spark.read.csv("iris.csv", inferSchema = True, header = True)
# 데이터를 sselect
spark.sql("SELECT * FROM iris_df LIMIT 5").show()
# AnalysisException: Table or view not found: iris_df; line 1 pos 14;
```

- 하지만 위의 sql 은 작동하지가 않습니다. 
  - 그 이유는 바로 , SQL 을 적용할수 있는 객체를 별도로 만들지 않았기 떄문입니다.

```python
iris_df.createOrReplaceTempView("iris")
spark.sql("SELECT * FROM iris LIMIT 5").show()
#+------------+-----------+------------+-----------+-------+
#|sepal.length|sepal.width|petal.length|petal.width|variety|
#+------------+-----------+------------+-----------+-------+
#|         5.1|        3.5|         1.4|        0.2| Setosa|
#|         4.9|        3.0|         1.4|        0.2| Setosa|
#|         4.7|        3.2|         1.3|        0.2| Setosa|
#|         4.6|        3.1|         1.5|        0.2| Setosa|
#|         5.0|        3.6|         1.4|        0.2| Setosa|
#+------------+-----------+------------+-----------+-------+
```

- 위처럼 `createOrReplaceTempView` 라는 명령어를 이용해서, view 를 만든 뒤에 , 쿼리를 적용하는 모습입니다.
  - 그 결과 위처럼 제대로 적용되는것을 볼 수 있어요!

> ## 전역 임시 뷰  (GlobalTempView)

- 스파크 SQL의 임시 뷰는 기본적으로 세션 내에서만 유효합니다. 
  - 즉, 임시 뷰를 생성한 세션이 종료되면 사라집니다. 
- 모든 세션에서 공유할 수 있는 임시 뷰를 만들고 스파크 애플리케이션을 종료하기 전까지 이것을 유지하려면, 전역 임시 뷰를 생성하여 사용해야 합니다. 
  - 전역 임시 뷰는 시스템 데이터베이스에서 `global_temp`로 저장되므로, 이를 참조하기 위해서는 여기에 맞춰서 전체 이름을 지정해 주어야 합니다. (예: `SELECT * FROM global_temp.view1`.)

````python
# DataFrame을 전역 임시 뷰에 등록합니다.
df.createGlobalTempView("people")

# 전역 임시 뷰는 시스템 데이터베이스에 `global_temp` 라는 이름으로 등록됩니다.
spark.sql("SELECT * FROM global_temp.people").show()
# +----+-------+
# | age|   name|
# +----+-------+
# |null|Michael|
# |  30|   Andy|
# |  19| Justin|
# +----+-------+

# 전역 임시 뷰는 다른 SparkSession에서도 사용할 수 있습니다.
spark.newSession().sql("SELECT * FROM global_temp.people").show()
# +----+-------+
# | age|   name|
# +----+-------+
# |null|Michael|
# |  30|   Andy|
# |  19| Justin|
# +----+-------+
````

> ## Summary

-  위에서와 같이 스파크의 SQL 실행을 하기 위해서 뷰를 만들 수 있었습니다.

Hide

**Reference**

- <https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.createOrReplaceTempView.html>



