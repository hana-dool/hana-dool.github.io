---
title:  "Cross validation of Bayesian Model"
excerpt: "Cross validation"
categories:
  - Bayes
last_modified_at: 2021-11-01

toc: true
toc_label: "Table Of Contents"
toc_icon: "cog"
toc_sticky: true

use_math: true
---

 베이지안의 경우 Cross Validation 이 사뭇 다르게 진행됩니다. 여기에서는 어떻게 다르게 진행되는지에 대해서 알아봅시다.
{: .notice--warning}

# [Expected log predictive density of a model](#link){: .btn .btn--primary}{: .align-center}

> ## Evaluation model 

- 우리는 Posterior Prediction of two models 을 비교하고 싶을 것입니다. 
  - 당연히 Likelihood 의 선택 , Prior 의 선택 등에 따라 Model 은 달라질 것이고 , 이들을 비교하고자 하는것은 당연한 욕구이니까요! 
- 먼저 평가 하고자 하는 모델이 $\mathcal{M}_1$ 이라고 하고, given data 는 $y$ 라고 합시다.
- 만약 new data 가 posterior distribution 에 대하여 잘 설명된다면, posterior predictive distribution 은 매우 좋다고 할 수 있습니다. (예측을 잘 한것이니까요)
  - $y_{pred}$ 는 True 분포인 $p_t$ 에서 나왔다고 가정합시다. 
  - 만약 Predictive 가 좋은 녀석이라면 다음의 값은 매우 높을 것입니다.

$$\begin{equation} u( \mathcal{M}_1, y_{pred}) = \log p(y_{pred}| y, \mathcal{M}_1) \tag{17.1} \end{equation}$$

- 하지만 이때 Bayes Fator 과는 다르게 위의 등식에는 Prior 가 없어 보입니다. 그렇다면 위의 모델링은 Prior 를 아예 이용하지 않는 방법일까요? 
  - 그러나 prior 도 여기에서 숨겨진 역할을 합니다. 
  - 왜냐하면 Posterior Predictive distribution 은 posterior distribution 인 $p(\Theta\mid y)$ 에 기초하고 있으며,  이러한 Posterio 분포는 Bayes Rule 에 의해 Prior 과 Likelihood 가 합쳐진 행태이기 떄문입니다. 

$$\begin{equation} p(y_{pred}\mid y )=\int_\Theta p(y_{pred}\mid \Theta) p(\Theta\mid y)\, d\Theta \tag{17.2} \end{equation}$$

- 이떄 주어진 데이터를 고려할때에, 새 데이터 $y_{pred}$ 는 위와 같이 예측이 됩니다. 
  - 우리가 어떤 모델을 사용했는지까지($\mathcal{M_1}$) 위의 식에 넣게 되면 아래와 같은 식이 나옵니다.

$$\begin{equation} p(y_{pred}\mid y,  \mathcal{M}_1)=\int_\Theta p(y_{pred}\mid \Theta, \mathcal{M}_1) p(\Theta\mid y, \mathcal{M}_1)\, d\Theta \tag{17.2} \end{equation}$$

- 하지만 Unobserved data 인 $y_{pred}$ 는 True distribution 에서 나온, 알지 못하는 미치의 unobserved 값 이기 때문에 위의 값을 계산할 수가 없습니다.
  - 즉 우리는 이러한 $y_{pred}$ 에 대하여 marginal out 시켜서 $E[\log p(y_{pred} | y, \mathcal{M}_1)]$ 를 계산할 것입니다.

> ## elpd(Expected log predictive density)

- 아래의 값은 Expected log predictive density of model $\mathcal{M_1}$ 으로서, 위에서 $y_{pred}$ 를 알 수 없어서 그 대안으로 marginal out 시킨 값입니다.

$$\begin{equation} elpd = u(\mathcal{M}_1) = \int_{y_{pred}} p_t(y_{pred}) \log p(y_{pred} \mid y, \mathcal{M}_1) dy_{pred} \tag{17.3} \end{equation}$$

- 이떄에 $p_t$ 는 True distribution 입니다. 
- elpd 가 높은 값을 가진다는것은 prediction 이 data generating process 를 잘 나타내고 있음을 의미합니다. 
  - 왜냐하면 True 데이터에 대해서 높은 확률 (log likelihood) 으로 예측을 잘 하고 있다는 의미이니까요.
- 위의 17.3 식의 Intuition 은, 다음과 같습니다. 
  - 만약 $M_1$ 모델이 좋다면, 모든 Future data 에 대하여 그 likelihood 의 평균값은 높을것이다 ! 

> ## Estimation of $p_t$

- 하지만 이때에 한가지 맹점이 있는데요, 우리는 $p_t$ 를 절대로 모른다는 것입니다! 
  - $p_t$ 를 알면 이 값을 그냥 predictive 한 값으로 썻겠죠.. $p_t$ 는 True Generating model 인걸요..
- 그러므로 이러한 $p_t$ 를 Proxy 하기 위하여 Observed data 를 사용하게 됩니다. 
  - 즉 Observed data 가 어쩃든 $p_t$ 에서 나왔으므로, 이를 이용하여 근사하겠다는 것입니다.  (MonteCarlo Approximation)
- 즉 우리는 이러한 elpd 를 근사하기 위하여 아래와 같이 근사식을 씁니다. 

$$\begin{equation} lpd = \frac{1}{N} \sum_{n=1}^{N} \log p(y_n|y, \mathcal{M}_1) \tag{17.4} \end{equation}$$

- 하지만 ! lpd 는 elpd 를 overestimate 합니다.
  - 왜냐하면 모델 Fitting 할때에 y 데이터를 이용하는데, y 데이터 안에 $y_n$ 이 있기 떄문이죠.
  - 즉 Training 데이터를 이용해 Train data 를 예측한것인데 , 이러면 당연히 예측확률값도 높겠죠? 

> Note

- 사실 위와 같은 이유로, Posterior Predictive Check 가 긍정적인 값을 자주 내놓게 되는 이유중에 하나입니다. 
  - 하지만 Posterior Predictive Check 도 통과하지 못하는 모델이면 정말 쓰레기 모델이라고 생각할 수 있다는 점에서, 여전히 유용하긴 합니다. 
- 그러므로 우리는 이러한 Optimistic 을 제거하기 위하여 K-fold 를 만들게 되는데... 

# [K fold and LOOCV](#link){: .btn .btn--primary}{: .align-center}

> ## Idea

- 위에서 예고했던데로, 그대로 elpd 의 추정량으로 lpd 를 사용하면 너무 긍정적으로 평가하게 된다는 부작용이 있었습니다. 
- 그러므로 우리는 다음과 같이 K-CV를 이용합니다.

> ## K-fold cross validation

- K - fold Cross validation (K - fold - CV) 방법론의 순서는 다음과 같습니다.
  - N 개의 Observation 을 K 개의 집단으로 나눕니다.
  - $D_1,D_2 ...$ 의 Dataset 집합이 생기는데요, 이떄 $D_{-k}$ 를 k번쨰 Dataset 을 제외한 나머지 데이터셋이라 가정합니다.
  - 1 부터 k 까지의 값에 대해서 $D_{-i}$ 를 이용해 모델을 Fitting 하고 $D_i$ 에 대해서 평가하는 작업을 반복해서 모델의 성능을 평가하게 됩니다. 이 방법을 k-fold 라 합니다. 
- LOO-CV 방법은 K=N 일떄의 방법으로, 이러한 추정을 하나하나 데이터에 대해서 실시합니다.
  - 이러한 LOOCV 를 이용한 elpd 의 추정을  아래와 같이 정의됩니다.

$$\begin{equation} \widehat{elpd} =  \frac{1}{N} \sum_{n=1}^{N} \log  p(y_n| D_{\backslash n}, \mathcal{M}_1) \tag{17.5} \end{equation}$$

- 위 (17.5) 의 equation 에서 각각의 $y_n$ 은 일종의 validation fold 에 들어가게 된다고 생각하시면 됩니다. 
  - 그리고 이러한 $y_n$ 을 평가하기 위해서는 $D_{\backslash n}$ 에서 Fittig 된 모델을 쓰게 됩니다. 

> ## Pointwise Predicive and Estimation

- Vehtari, Gelman, and Gabry ([2017](https://vasishth.github.io/bayescogsci/book/k-fold-and-leave-one-out-cross-validation.html#ref-vehtariPracticalBayesianModel2017)[b](https://vasishth.github.io/bayescogsci/book/k-fold-and-leave-one-out-cross-validation.html#ref-vehtariPracticalBayesianModel2017)) 는 expected log pointwise predictive density of observation $y_n$ 을 다음과 같이 정의하였습니다. 

$$\begin{equation} \widehat{elpd}_{n} =  \log  p(y_n| D_{\backslash n} , \mathcal{M}_1) \end{equation}$$

- Model comparison 을 비교할떄에는$\sum elpd_n$ 을 이용하게 됩니다. (1/N 이 없음)
  - 이떄에 주의할점은 $\widehat{elpd}$ 값이 '클수록' 좋다는 것입니다! (다른 error 값은 작을수록 좋은데 말이죠.)
  - 그래서 $-2\times \widehat{elpd}$ 값을 LOO 값 대신 쓰디고 합니다. (LOO information Criterion)
- 위에서 K-fold 를 써서 elpd 를 근사하게 되면 K = N 일떄가 제일 idealy 정확합니다. 
  - 그러므로 LOO-CV 가 K-fold 보다 더 선호되는 방법입니다. 
  - 이러한 LOO-CV 의 좋은범은 바로 Robustness 입니다.
    - 왜냐하면 Training set 은 real data 와 비슷한데에다가 , test 데이터는 fitting 에 쓰이지 않기 떄문입니다.
  - 하지만 안좋은점은.. 바로 계산 복잡도 입니다. 
- 그러므로 이러한 방법을 해결하기 위하여 PSIS-LOO 방법이 개발되었습니다. 
  - (PSIS-LOO; Vehtari and Gelman [2015](https://vasishth.github.io/bayescogsci/book/k-fold-and-leave-one-out-cross-validation.html#ref-VehtariGelman2015Pareto); Vehtari, Gelman, and Gabry [2017](https://vasishth.github.io/bayescogsci/book/k-fold-and-leave-one-out-cross-validation.html#ref-vehtariPracticalBayesianModel2017)[b](https://vasishth.github.io/bayescogsci/book/k-fold-and-leave-one-out-cross-validation.html#ref-vehtariPracticalBayesianModel2017)),
- 이 방법은 LOO-CV 를 근사하는 방법론으로서 Pareto Smooth impotance Sampling 을 이용합니다. 
- 물론 여전히 문제가 있다고 말하고 있기는 한데요, 더 자세한것은 내용을 뛰어 넘는것같아 여기서 Cut ! 

## **reference**

- <https://vasishth.github.io/bayescogsci/book/k-fold-and-leave-one-out-cross-validation.html>

위와 같이 베이즈 방법론을 평가하는 방법을 알아보았습니다. MCMC diagnotic 이 아니라 Model Comparison 이라 Review 하면서 훨씬 기분이 좋았네요 
{: .notice--success}

