---
title:  "Wald Tests"
excerpt: "Likelihood based Test"
categories:
  - Stat_Testing
date : 2021-09-20 15:00:00 +0900
last_modified_at: 2021-09-20

toc: true
toc_label: "Table Of Contents"
toc_icon: "cog"
toc_sticky: true

use_math: true
---

 Wald 테스트는 다양한곳에 이용됩니다. 이 테스트가 과연 어떤것인지 알아봅시다.
{: .notice--warning}

# [Wald Tests](#link){: .btn .btn--primary}{: .align-center}

> ## Recall

![png](/assets/images/Stat/59_1.png)

- 위의 결과를 해석해봅시다. 

> $\sqrt{n} (\hat{\theta_n}-\theta_0) \xrightarrow{D} N(0,I(\theta_0))$ 

- Under Regularity Condition 에 의하면 , MLE 는 Assymptotic 하게 위의 관계를 따릅니다. 

> $n^{1/2}I^{1/2}(\theta_0)(\hat{\theta_n}-\theta)^2 \xrightarrow{D}{\chi_1}^2$

-  이 공식은 Continuous Mapping Thm 에 의해 성립합니다. 

![png](/assets/images/Stat/59_2.png)

- 현재, 위의 g function 은 squared 함수로, 당연히 Continuous 합니다. 즉 , 위의 관계가 성립합니다.

> $I(\theta_0) \to I(\hat{\theta_n})$

- 위의 치환은 , $\hat{\theta_n}$ 이 Consistence estimator 라는 가정과 Slutsky Thm 을 이용합니다.

![png](/assets/images/Stat/59_5.png)

> ## Wald Test 

![png](/assets/images/Stat/59_3.png)

- 위 식은, 좀 더 일반적인 Multivariate 로 확장할 수 있습니다.

![png](/assets/images/Stat/59_4.png)

> ## Examples 

![png](/assets/images/Stat/59_6.png)

- 우선 , 위에서 MLE Estimator for $\theta$ 는 쉽게 $\hat{\theta} = -n/\sum logX_i$ 임을 알  수 있습니다.
- 이제, $I(\hat{\theta}) = E[-\frac{\partial^2{log(f(x;\theta))}}{\partial\theta^2} ]$ 를 이용하여, , 추정해본다면 , $1/\hat{\theta^2}$ 가 됩니다.
- 이제 MLE 의 성질에서 $\sqrt{n} I^{1/2}(\hat\theta)(\hat{\theta} - \theta) \sim N(0,1^2))$ 임을 알 수 있습니다. 이를 위의 값을 이용하여 넣어보다면 
- $\sqrt{n} (1/\hat{\theta}) (\hat{\theta} - 1) \sim N(0,1^2)$
- 이제 양변에 제곱을 통해서 Wald Test 의 형태로 만들어줍시다. 
- Reject $H_0$ if $n(1-\frac{1}{\hat{\theta}})^2 \ge \chi_{1-a;1}$

---

**Reference**

- 연세대 수리통계학 강의
- WIkipedia 

 Likelihood Test 는 기본적으로, 검사하고자 하는 값이 MLE 로 추정되었다면 Large Sample 일 떄에 (Converge in Distribution 이 성립해야 하므로) Testing 할 수 있는 방법론입니다. 그러므로, Assumption 자체가 매우 느슨하므로 많이 쓰이는 방법중 하나입니다.
{: .notice--success}

