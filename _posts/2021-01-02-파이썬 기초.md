---
title:  "파이썬 데이터 기초분석"
excerpt: "분석을 위한 기초를 알아봅시다."
categories:
  - Python
tags:
  - 전처리
last_modified_at: 2021-01-02T22:00:00

toc: true
toc_label: "Table Of Contents"
toc_icon: "cog"
toc_sticky: true
---

```python
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
data=sns.load_dataset('iris')
```

# 분석을 위한 데이터처리

## Train/Test set 분할하기


```python
data.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal_length</th>
      <th>sepal_width</th>
      <th>petal_length</th>
      <th>petal_width</th>
      <th>species</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
  </tbody>
</table>
</div>




```python
y =data['species'] # Y target 을 species 로 잡겠다.(classification)
X =data.drop('species',axis=1) # x 변수는 species 를 제외한 나머지
```


```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y,train_size=0.8, random_state=42)
# X_train, X_test, y_train, y_test 의 순서가 중요하다. 
# train_size : train set 의 size 비율을 얼마나 잡을것인가. 대게 0.7~0.8 을 잡는다.
# random_state : 다시 실행해도 결과를 같게하기 위해 random_state 를 설정한다.
```

# classification 성능평가

## confusion_matrix(y_true, y_pred)

confusion matrix : 정답 클래스는 행(row)으로 예측한 클래스는 열(column)로 나타낸다. <br>
- 즉 diagonal 에 있는 수는 예측을 잘 한 경우이다
- 사이킷런 패키지에서 제공하는 confusion_matrix 명령을 사용할 때는 클래스 순서가 0, 1, 2, ... 순서로 출력되기때문에 주의하자


```python
y_true = [1, 1, 2, 3, 3, 3, 3]
y_pred = [1, 1, 2, 2, 2, 3, 3]
```


```python
from sklearn.metrics import confusion_matrix
confusion_matrix(y_true, y_pred)
```




    array([[2, 0, 0],
           [0, 1, 0],
           [0, 2, 2]], dtype=int64)



즉 참값이 3 일때에 이 모델은 예측을 못 하고 있음을 볼 수 있다.

## accuracy_score(y_true, y_pred)

정확도(accuracy)는 전체 샘플 중 맞게 예측한 샘플 수의 비율을 뜻한다. 높을수록 좋은 모형이다. 일반적으로 학습에서 최적화 목적함수로 사용된다


```python
y_true = [1, 1, 2, 2, 2]
y_pred = [1, 1, 2, 2, 3]
```


```python
from sklearn.metrics import accuracy_score
accuracy_score(y_true,y_pred)
```




    0.8



## precision_score(y_true, y_pred)

A class 라고 예측한 것들 중 실제로 A class 인 것의 비율

그래서 TEST 의" '정확도' score 라고 한다.

hyper parameter 

- macro: 단순평균
- weighted: 각 클래스에 속하는 표본의 갯수로 가중평균


```python
y_true = [1, 1, 1, 2, 2, 2, 3, 3, 3, 3]

y_pred = [1, 1, 1, 2, 2, 1, 2, 2, 2, 3]
```


```python
# averge =None 을 해야 multi label 에서 작동한다.
# 원래 precision_score 는 이진분류 (양성,음성) 에서 만들어진 score 라 지금경우 label 이 3개인 경우 3개의 값을 나타낸가.
from sklearn.metrics import precision_score
precision_score(y_true,y_pred,average=None)
```




    array([0.75, 0.4 , 1.  ])




```python
precision_score(y_true,y_pred,average='weighted')
```




    0.745



## recall_score(y_true, y_pred)

실제 A 클래스에 속한 표본 중에 A 클래스에 속한다고 출력한 표본의 수의 비율을 뜻한다.

그래서 test 의 '재현율' 이라고 한다. 실제 클래스의 값들을 모두 뽑아내는지에 대한 score 이다.


```python
y_true = [1, 1, 1, 2, 2, 2, 3, 3, 3, 3]
f1_score(y_true, y_pred)
y_pred = [1, 1, 1, 2, 2, 1, 2, 2, 2, 3]
```


```python
from sklearn.metrics import recall_score
recall_score(y_true,y_pred,average=None)
```




    array([1.        , 0.66666667, 0.25      ])




```python
recall_score(y_true,y_pred,average='weighted')
```




    0.6



## F1_score(y_true, y_pred)

정밀도와 재현율의 가중조화평균(weight harmonic average)을 F점수(F-score)라고 한다.

F1 score는 데이터 label이 불균형 구조일 때, 모델의 성능을 정확하게 평가할 수 있으며, 성능을 하나의 숫자로 표현할 수 있습니다

베타가 1인 경우를 특별히 F1점수라고 한다. F1=2⋅precision⋅recall/(precision+recall)

높을수록 좋음


```python
y_true = [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2]

y_pred = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
```


```python
from sklearn.metrics import f1_score
f1_score(y_true,y_pred, average='weighted')
```




    0.7363636363636363




```python
y_true = [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2]

y_pred = [1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2]
```


```python
from sklearn.metrics import f1_score
f1_score(y_true,y_pred,average='weighted')
```




    0.8371212121212122




```python
# 위와 같이 틀린 횟수는 똑같지만, 적은 데이터데 대해 작 예측할때 f1 score 가 높은것을 볼 수 있습니다.
```

## classification_report(y_true, y_pred)


```python
y_true = [1, 1, 1, 2, 2, 2, 3, 3, 3, 3]

y_pred = [1, 1, 1, 2, 2, 1, 2, 2, 2, 3]
```


```python
from sklearn.metrics import classification_report

class_name = ['class 1', 'class 2', 'class 3']

print( classification_report(y_true,y_pred, target_names= class_name ) )
```

                  precision    recall  f1-score   support
    
         class 1       0.75      1.00      0.86         3
         class 2       0.40      0.67      0.50         3
         class 3       1.00      0.25      0.40         4
    
        accuracy                           0.60        10
       macro avg       0.72      0.64      0.59        10
    weighted avg       0.74      0.60      0.57        10
    
    

# 모형 최적화(Hyperparameter)

## GridSearchCV

### 단일 parameter 


```python
# 데이터 생성
from sklearn.datasets import load_boston
boston = load_boston()
X = boston.data
y = boston.target
```


```python
from sklearn.linear_model import Lasso, Ridge
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import GridSearchCV

ridge = Ridge()
alphas = np.linspace(1, 500, 200) # 추정하려는 parameter 범위
parameters = {'alpha': alphas } # 추정하려는 parameter(이때 이름은 모델의 parameter default 이름과 똑같이 넣어야 한다.)

model = GridSearchCV(estimator = ridge, param_grid = parameters, scoring='neg_mean_squared_error',cv=5)
# estimator : 모델
# param_grid : 추정하고싶은 파라미터 이름(str)을 key 로. lists of parameter settings 을 value 로 하는 dictionary
# scoring : evaluate the predictions on the test set
#         : (default) model 이 가지고있는 default evaluation criterion 를 쓴다
#         : model has score method providing a default evaluation criterion for the problem they are designed to solve 
#         : ‘accuracy’ = metrics.accuracy_score (classification)
#         : ‘r2’ = metrics.r2_score (regression)
#         : ‘neg_mean_squared_error’ : metrics.mean_squared_error (regression)
#         : 자세한건 scoring parameter 
# cv : k-fold validation 에서 k
#    : (default)3-fold cross validation
model.fit(X,y)
# fitting 을 해야 위에서 설정한 객체가 그대로 적용이 되면서 비로소 best 한 parameter 를 찾아준다.

print(model.best_params_) # 우리가 추정한 best parameter
print(model.best_score_) # 우리가 지정한 scoring 에 기반한 제일 좋은 score

```

    {'alpha': 151.45226130653265}
    -29.753677540045423
    


```python
# CV result 분석
```


```python
result = pd.DataFrame(model.cv_results_)[['param_alpha','mean_test_score']]
plt.plot('param_alpha','mean_test_score',data=result,)
```




    [<matplotlib.lines.Line2D at 0x22fe343e278>]




    
![png](output_44_1.png)
    



```python
print(model.best_params_) # 우리가 추정한 best parameter
print(model.best_score_) # 우리가 지정한 scoring 에 기반한 제일 좋은 score
```

    {'alpha': 151.45226130653265}
    -29.753677540045423
    


```python
# (note)
# 근데 왜 mse 가 음수인가요? 
# 사이킷런의 교차 검증 기능은 scoring 매개변수에 (낮을수록 좋은) 비용 함수가 아니라 (클수록 좋은) 효용 함수를 기대합니다. 
# 그래서 평균 제곱 오차(MSE)의 반댓값(즉, 음숫값)을 계산하는 neg_mean_squared_error 함수를 사용
```

### 여러개 parameter 


```python
#데이터 생성
data=sns.load_dataset('iris')
y =data['species'] # Y target 을 species 로 잡겠다.(classification) # 이 때에 1dim array 로 해주어야한다.
X =data.drop('species',axis=1) # x 변수는 species 를 제외한 나머지
X_train, X_test, y_train, y_test = train_test_split(X, y,train_size=0.8, random_state=42)
```


```python
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV

scv = SVC()
param_grid ={'C' : [0.001,0.01,0.1,1,10,100], 'gamma' : [0.001,0.01,0.1,1,10,100] }
model = GridSearchCV(scv,param_grid,cv=5)
# scoring 은 default 이므로 model 의 자체 scoring 을 이용해 최적화를 하게 된다. 
# 이제 model=GridSearchCV 는 GridSearch 를 통해 최적화된 parameter 를 이용한 scv model 이 합쳐진 것이 된다. 
model.fit(X,y)
print(model.best_params_) # 우리가 추정한 best parameter
print(model.best_score_) # 우리가 지정한 scoring 에 기반한 제일 좋은 score
```


    ---------------------------------------------------------------------------

    NameError                                 Traceback (most recent call last)

    <ipython-input-1-6a7c6e40a25e> in <module>
          5 grid_search = GridSearchCV(scv,param_grid,cv=5)
          6 # scoring 은 default 이므로 model 의 자체 scoring 으로 들어간다.
    ----> 7 grid_search.fit(X,y)
          8 print(grid_search.best_params_) # 우리가 추정한 best parameter
          9 print(grid_search.best_score_) # 우리가 지정한 scoring 에 기반한 제일 좋은 score
    

    NameError: name 'X' is not defined



```python

```
