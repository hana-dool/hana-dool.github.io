---
title:  "type.StructType"
excerpt: "데이터의 스키마 명시하기"
categories:
  - Spark_other_method
last_modified_at: 2021-11-26

toc: true
toc_label: "Table Of Contents"
toc_icon: "cog"
toc_sticky: true

use_math: true
---

스파크의 기본만 한번 알아봅시다.
{: .notice--warning}

# [Schma](#link){: .btn .btn--primary}{: .align-center}

> ## 스키마

> pyspark.sql.types.StructType

- Struct type, consisting of a list of [`StructField`](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructField.html#pyspark.sql.types.StructField).
- This is the data type representing a `Row`.
- Iterating a [`StructType`](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html#pyspark.sql.types.StructType) will iterate over its [`StructField`](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructField.html#pyspark.sql.types.StructField)s. A contained [`StructField`](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructField.html#pyspark.sql.types.StructField) can be accessed by its name or position.

> Note

- 이전에 스키마가 명시가 되어있지 않을때에는 Spark 가 데이터들을 어느정도 살펴보고, 그에 따라서 알아서 그 타입을 정해준다고 한 적이 있습니다.
  - 하지만 이렇게 자동으로 정해주는경우가 틀릴때가 있어서 우리가 직접 스키마를 명시해야할 때가 있을것입니다. 이럴때에는 어떻게 해야할까요?


- 우리가 직접 스키마를 명시한 `DataFrame`는 아래의 과정을 거쳐서 생성할 수 있습니다.

1. 기존의 RDD에서 튜플 또는 리스트로 이루어진 RDD를 생성합니다;
2. 1단계에서 생성한 RDD의 튜플 또는 리스트 구조와 일치하는 `StructType`으로 나타낸 스키마를 생성합니다.
3. `SparkSession`의 `createDataFrame` 메소드를 사용하여 RDD에 이 스키마를 적용합니다.

> ## 스키마 만들기

```python
from pyspark.sql import Row
from pyspark.sql.types import StructField, StructType, StringType, LongType

# 내가 정의한 스키마
myManualSchema = StructType([
  StructField("some", StringType(), True),
  StructField("col", StringType(), True),
  StructField("names", LongType(), False)
])
```

- 이때 위를 잘 보면 `myManualSchema` 가 제가 정의한 스키마입니다. 이때 이 스키마는 오른쪽의 StructType 이라는 객체로 설명되고 있는데요, 이 데이터 형식은 뭘까요?
  - StructType(fields): StructFields(필드)의 시퀀스에서 설명하는 구조체의 값을 나타냅니다.
  - StructField(name, dataType, nullable): StructType의 필드를 나타냅니다. 필드의 이름은  `name` 표시됩니다. 필드의 데이터 형식은 dataType으로 표시됩니다. `nullable` 값이 null일 수 있는지 지정하는 boolean 값을 가집니다.
- 즉 , 스키마는 여러 개의 StructField 타입 필드로 구성된 StructType 객체로 구성되게 됩니다. 
  - 위의 예시를 하나 가지고 오겠습니다. `StructField("some", StringType(), True)` 의 의미는 다음과 같습니다.
  - 이름 : 'some'
  - 타입 : StringType (문자열)
  - Null을 가질 수 있는가? : True(가질 수 있음)
- 위처럼 우리는 데이터프레임을 만들기 전에 스키마를 얻을 수 있었습니다.
  - 이러한 스키마를 적용해서 데이터 프레임을 어떻게 하면 만들 수 있을까요? 

> ## 스키마를 적용하여 데이터프레임 만들기

```python
myRow = Row("Hello", None, 1)
myDf = spark.createDataFrame([myRow], myManualSchema)
myDf
# DataFrame[some: string, col: string, names: bigint]
myDf.show()
#+-----+----+-----+
#| some| col|names|
#+-----+----+-----+
#|Hello|null|    1|
#+-----+----+-----+
```

- 위에서 우리는 `createDataFrame` 의 함수를 쓰게 되는데요, 이것에 대해서는 따로 게시글을 만들었으니, 그것을 참고하면 좋을것 같습니다.
- 위처럼 우리는 `createDataFrame` 를 이용하여 이전에 정의한 스키마를 데이터 프레임에 적용하게 됩니다.
  - 우리가 의도한 스키마대로 잘 적용되는것을 볼 수 있습니다

---

**Reference**

- 스파크 완벽 가이드
- <https://spark-korea.github.io/docs/sql-getting-started.html#creating-datasets>
- <https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.SparkSession.createDataFrame.html>



