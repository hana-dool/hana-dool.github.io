---
title:  "col.alias"
excerpt: "column 의 별칭 지정하기"
categories:
  - Spark_other_method
last_modified_at: 2021-11-25

toc: true
toc_label: "Table Of Contents"
toc_icon: "cog"
toc_sticky: true

use_math: true
---

select 와 expr 을 통하여 SQL 을 사용해보자
{: .notice--warning}

# [select and seletExpr](#link){: .btn .btn--primary}{: .align-center}

> ## alias 

- 이는 우리가 불러오는 column 의 이름을 변형할때에 사용합니다.
- 기본적으로 정의는 다음과 같습니다.

> pyspark.sql.Column.alias

- Returns this column aliased with a new name or names (in the case of expressions that return more than one column, such as explode).
- 즉 column 의 메서드로서, 기존의 column 이름을 바꾸는 메서드입니다.

> Example

```python
df.select(df.name, (df.age + 10).alias('age')).collect()
# [Row(name='Alice', age=12), Row(name='Bob', age=15)]
```

```python
iris_df.select(col('sepal_length').alias('new')).show()
#+---+
#|new|
#+---+
#|5.1|
#|4.9|
#|4.7|
#....
```



**Reference**

- 스파크 완벽 가이드
- https://spark.apache.org/docs/latest/sql-getting-started.html

