---
title:  "lit"
excerpt: "리터럴값 표현"
categories:
  - Spark_Function
last_modified_at: 2021-11-25

toc: true
toc_label: "Table Of Contents"
toc_icon: "cog"
toc_sticky: true

use_math: true
---

select 와 expr 을 통하여 SQL 을 사용해보자
{: .notice--warning}

# [select and seletExpr](#link){: .btn .btn--primary}{: .align-center}

> ## lit

- 스파크는 lit 을 이용하여 리터럴값을 표현합니다.

```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, lit
import pandas as pd

spark = SparkSession.builder.getOrCreate()

df_test = pd.DataFrame({
    'a': [1, 2, 3],
    'b': [10.0, 3.5, 7.315],
    'c': ['apple', 'banana', 'tomato']
})

df_spark = spark.createDataFrame(df_test)

df_new = df_spark.select(
    col('a'),
    col('b'),
    lit(1).alias('d') # 1
)
df_new.show()

#+---+-----+---+
#|  a|    b|  d|
#+---+-----+---+
#|  1| 10.0|  1|
#|  2|  3.5|  1|
#|  3|7.315|  1|
#+---+-----+---+
```

- 기본적으로 위처럼 df 의 'd' 열이 리터럴값이 됩니다.
- 어떠한 상수나, 프로그래밍으로 생성된 변숫값이 특정 칼럼값보다 큰지 확일할때에 리터럴값을 이용하고는 합니다.

**Reference**

- 스파크 완벽 가이드
- https://spark.apache.org/docs/latest/sql-getting-started.html

