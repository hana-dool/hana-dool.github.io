---
title:  "df.limit"
excerpt: "데이터 출력 수 제한하기"
categories:
  - Spark_df_method
last_modified_at: 2021-11-26

toc: true
toc_label: "Table Of Contents"
toc_icon: "cog"
toc_sticky: true

use_math: true
---

데이터타입 바꾸기
{: .notice--warning}

# [df.limit](#link){: .btn .btn--primary}{: .align-center}

> ## 공식문서

> pyspark.sql.DataFrame.limit(num)

- Limits the result count to the number specified.

> Example

```python
df.limit(1).collect()
[Row(age=2, name='Alice')]
df.limit(0).collect()
[]
```

> ## 설명

- Dataframe 에서 추출한 로우 수를 제한하여 분석해야할 수 있습니다. 이러한 경우에 limit 을 사용합니다.
- 이때 의문이 하나 들 수도 있는, 과연 show() 와는 뭐가 다른걸까요?

```python
iris_df.show(5).where('petal_width>2.1')
# AttributeError: 'NoneType' object has no attribute 'where'
```

- 위와 같이 show() 는 단지 출력값을 '표시' 할 뿐입니다.
  - 마치  파이썬의 print 처럼요!
- 그러므로 여기에서 변환을 하려고 해봤자,출력값이 없어 Nonetype 이므로 변환을 하지 못합니다.
  - 즉 우리는 아래처럼 계산해야 합니다.

```python
iris_df.limit(5).where('sepal_width > 3').show()
#+------------+-----------+------------+-----------+-------+
#|sepal_length|sepal_width|petal_length|petal_width|variety|
#+------------+-----------+------------+-----------+-------+
#|         5.1|        3.5|         1.4|        0.2| Setosa|
#|         4.7|        3.2|         1.3|        0.2| Setosa|
#|         4.6|        3.1|         1.5|        0.2| Setosa|
#|         5.0|        3.6|         1.4|        0.2| Setosa|
#+------------+-----------+------------+-----------+-------+
```


---

**Reference**

- 스파크 완벽 가이드
- 스파크 공식 가이드북



