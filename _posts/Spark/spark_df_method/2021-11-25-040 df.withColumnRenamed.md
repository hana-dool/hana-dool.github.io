---
title:  "df.withColumnRenamed"
excerpt: "column 이름 바꾸기"
categories:
  - Spark_df_method
last_modified_at: 2021-11-25

toc: true
toc_label: "Table Of Contents"
toc_icon: "cog"
toc_sticky: true

use_math: true
---

select 와 expr 을 통하여 SQL 을 사용해보자
{: .notice--warning}

# [select and seletExpr](#link){: .btn .btn--primary}{: .align-center}

> ## withColumnRenamed

> DataFrame.withColumnRenamed(existing, new)

- Returns a new [`DataFrame`](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.html#pyspark.sql.DataFrame) by renaming an existing column. This is a no-op if schema doesn’t contain the given column name.
- Parameters
  - existing : str
    - string, name of the existing column to rename.
  - new : str
    - string, new name of the column.

> Note

- 컬럼명을 변경할때에 사용할 수 있는 방식입니다.

```python
df.show(3)
#+-----------------+-------------------+-----+
#|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|
#+-----------------+-------------------+-----+
#|    United States|            Romania|   15|
#|    United States|            Croatia|    1|
#|    United States|            Ireland|  344|
#+-----------------+-------------------+-----+
df.withColumnRenamed('DEST_COUNTRY_NAME','new').show(3)
#+-------------+-------------------+-----+
#|          new|ORIGIN_COUNTRY_NAME|count|
#+-------------+-------------------+-----+
#|United States|            Romania|   15|
#|United States|            Croatia|    1|
#|United States|            Ireland|  344|
#+-------------+-------------------+-----+
```

- 위처럼 기존의 column 이름을 새로운 이름으로 바꿀 수 있습니다.

**Reference**

- 스파크 완벽 가이드
- https://spark.apache.org/docs/latest/sql-getting-started.html

