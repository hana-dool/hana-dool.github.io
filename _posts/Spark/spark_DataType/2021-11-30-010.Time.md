---
title:  "Time and Data Datatype"
excerpt: "날짜와 타임스탬프 데이터타입 다루기"
categories:
  - Spark_Datatype
last_modified_at: 2021-11-30

toc: true
toc_label: "Table Of Contents"
toc_icon: "cog"
toc_sticky: true

use_math: true
---

 데이터프레임
{: .notice--warning}

# [Time and Data Datatype](#link){: .btn .btn--primary}{: .align-center}

> ## 날짜와 타임스탬프 타입

- 날짜와 시간의 데이터타입은 매우 중요한 과제입니다. 
  - 계속해서 시간대를 확인해야 하고, 포멧이 올바르고 유효한지에 대해서 확인해야 합니다. 
- 포맷이 너무 많으면 관리도 힘들고 코드 짜기도 힙들것입니다. 
- 스파크는 이런 복잡성을 피하기 위하여 두가지 종류의 시간 관련 정보만 집중적으로 관리하게됩니다. 
  - 달력형태의 날짜 (data)
  - 날짜와 시간정보를 모두 가지는 Time Stamp

> inferschema

- 스파크의 경우 inferSchema 옵션을 이용하게 될 경우 날짜와 타임스탬프를 포함하여, 컬럼의 데이터 타입을 최대한 정확히 실별하려 합니다.
  - 즉 어느정도 스파크가 알아서 데이터타입을 읽을 수 있다는 것이죠
- 날자와 타임 스탬프를 다루는 작업은 문자열을 다루는 작업과 관련이 있습니다.
  - 날짜와 시간을 먼저 문자열로 저장하고, 런타임에서 날짜 타입으로 변환하는 경우가 많기 때문입니다. 

> 특이한 데이터 타입

- 스파크는 날짜와 시간을 최대한 올바르게 읽으려고 노력합니다.
- 만약 특이한 포맷의 날짜/시간 데이터를 쓰게 된다면, 각 단계별로 데이터 타입을 어떻게 유지하게 되는지를 잘 보고 트랜스포메이션을 적용해야 합니다.
  - ex : timestamptype 클래스는 초단위 정밀도까지만 지원합니다. 

> ## Example 

```python
from pyspark.sql.functions import current_date, current_timestamp
dateDF = spark.range(10)\
  .withColumn("today", current_date())\
  .withColumn("now", current_timestamp())
dateDF.createOrReplaceTempView("dateTable")
dateDF.printSchema()
#root
#|-- id: long (nullable = false)
#|-- today: date (nullable = false)
#|-- now: timestamp (nullable = false)
```

- 위의 코드는 오늘 날짜와 , 현재의 타임 스탬프를 구하는 에제입니다.
- 위 처럼 datatype 이 각각 date , timestape 가 되어있는것을 볼 수 있습니다. 

```python
cleanDateDF.filter(col('date') > lit('2017-12-10')).show()
```

- 위와 같이 date 의 경우에는 직접 `>` 를 통해서 비교가 가능합니다.

---

- **Reference**

- 스파크 완벽 가이드
- https://spark.apache.org/docs/latest/sql-getting-started.html
- https://stackoverflow.com/questions/64054282/what-do-the-sparksession-appname-and-getorcreate-functions-mean
- https://wikidocs.net/16565

