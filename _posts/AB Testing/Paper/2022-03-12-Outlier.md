---
title: "A Probabilistic, Mechanism-Indepedent Outlier Detection Method for Online Experimentation"
excerpt: "Outlier Detection 방법론 비교 (yahoo)"
categories:
  - AB_Paper
last_modified_at: 2022-03-12

toc: true
toc_label: "Table Of Contents"
toc_icon: "cog"
toc_sticky: true

use_math: true
typora-root-url: ../../../../hana-dool.github.io
---

 Sequential 하게 테스트를 하지만, 이에 대해서 
{: .notice--warning}

# [0.Abstract](#link){: .btn .btn--primary}{: .align-center}

> ## Abstract 

- 많은 기업들은 현재 사용자의 반응을 평가하기 위해서 Online Experiment 를 적극적으로 이용하고 있습니다.
- 하지만 이때 특이치가 있으면 실험의 결과해석이 다소 복잡해집니다. 
  - 특이치를 단순히 제거하자니, 메트릭에 따라 (ex : 페이지뷰) Normal 분포를 따르지 않기 때문에 이를 식별하는것으 다소 어렵습니다. 

- 이 논문에서는 이상치가 실험에 미치는 영향을 설명하고, 이상치 탐지의 중요성을 설명하고자 합니다.
- 또한 해결책으로 다양한 유형의 데이터에 대한 이상치 필터링을 처리하기 위한 일반적인 방법론을 소개합니다. 
- 마지막으로는 실제와 시뮬레이션된 웹 데이터를 기반으로 , 제안된 알고리즘이 다른 기존 방법보다 우수하다는것을 보여주려 합니다.

# [1.Introduction](#link){: .btn .btn--primary}{: .align-center}

> ## Outlier 탐지의 중요성

- A/B 테스트는 현재 Decision Rule 에 대한 Standard Rule 이 되었습니다. 
  - 아마존, 이베이, 페이스북, 구글, 그루폰, 링크드인, 마이크로소프트, 넷플릭스 등의 기업들이 활발히 사용중입니다. 

- 우리 회사(Yahoo) 에서는 매일 수백 건의 실험이 진행되고 있습니다. 
- 이때 실험 분석의 품질과 신뢰성은 적절한 제품 결정에 매우 중요합니다. 
- 실제로 이상치가 잘못된 분석 결과를 초래할 수 있다는 것을 알 수 있습니다.
  - 극단적인 경우 특이치는 실험 결과를 완전히 뒤바꿀수도 있습니다. 
  - 이는 표본 평균이 강력한 통계량이 아니며 표본 크기가 크더라도 특이치에 취약하기 때문입니다.


> ## Outlier 탐지의 어려움

> Normal 을 따르지 않는다.

- 웹 데이터 특이치를 탐지하는 데 있어 한 가지 문제는 데이터의 왜도입니다. 
- 전통적으로 특이치는 정규성 가정으로 식별됩니다. 
  - 일부 실무자는 평균으로부터의 3 표준 편차를 특이치 분계점으로 사용할 것을 권장합니다[10]. 
- 그러나 세션, 페이지 뷰 및 클릭을 포함하여 많은 실험 지표들은 Right Skewed 되어있어, Normal 가정을 한 상태에서 Outlier 처리를 하기가 힘듭니다.

> 명확한 경계가 없다.

- 또 다른 과제는 특이치와 일반 데이터 지점 사이의 명확한 경계가 부족하다는 것입니다.
- 이는 많은 클러스터 기반 알고리즘을 적용할 수 없다는것을 의미합니다. [11] [12]

> ## 논문에서 다루는 방법

- 본 논문에서, 우리는 이상치 탐지에 대한 통계적 접근방식을 이용해,  특이치와 정상 데이터 포인트 사이에 대해서 경계가 없더라도 잘 작동하는 방식을 제안하려고 합니다.
- 논문에서 제안된 제안된 방법은 completely distribution 중심이녀 outlier generating mechanism 과는 무관합니다. 
- 논문에서 제시한 방법은 데이터 오류, 웹 크롤러, 광고 인상 사기 및 광고 클릭 사기 등과 같은 다양한 유형의 이상치를 식별하는 데 유용합니다.
- 우리는 다음과 같은것들을 다루고자 합니다.
  - 실험 결과에 대한 특이치의 영향을 보여줌
  - 우측으로 편향된(Skewed) 카운트 데이터에 대한 이상치를 탐지하기 위해 OTPSM(샘플 최대값을 사용한 외부 테스트 절차)이라는 새로운 알고리즘을 도입합니다.

# [II. OUTLIERS IN ONLINE EXPERIMENTATION](#link){: .btn .btn--primary}{: .align-center}

> ## Intro

- 웹 데이터에는 여러 가지 이상값들이 있습니다.
  - 이러한 이상값은 데이터 오류, 웹 크롤링, Fraud 등으로부터 발생할 수 있습니다 [13] [14]. 
- 우리 회사에는 이러한 이상 징후와 부정 행위 탐지를 위한 내부적인 엔진이 있습니다. 
  - 이러한 탐지를 뚫고, 적은 수의 이상치만 통과되게 됩니다. 
- 이에 따라서 결과적으로 실험 분석에 사용되는 데이터는 대체로 깨끗합니다. 
- 이 절에서는 나머지 특이치가 여전히 엄격한 실험 분석에 위협이 된다는 것을 실제 사례로 설명할 것입니다. (결과는 추가적인 특이치 탐지 방법이 필요하다는 것을 시사합니다.)

> ## 실험 세팅

- Two sample A/B Experiment 을 시핼할때에는 Test Group 에는 30057 명의 유저가 있었고, Control 그룹에는 30600명의 유저가 할당되었습니다. 
- 이떄 Pages views per user 매트릭이 main metric 으로 선정되었습니다.
- 이때 샘플에 대해서 Pages View 메트릭은 왜도가 16.2 까지 높았습니다.
- 특이치 제거 방법을 적용하지 않았을때에는 Test 와 Control 의 차이는 -1.76 이고, P 값은  < 0.001 이였습니다.

> ## A. Outlier 가 실험 결과에 미치는 영향

- 일반적으로  two-sample univariate t-test  방법론이 적용됩니다.
- 이떄 $Y_i$ 를 $i^{th}$ 유저의 outcome metric 이라고 합시다. 
- 그리고 $X_i$ 를 test 와 Control 을 나타내는 Binary indicator 라고 합시다.
  - Test : 1 / Control : 0
- 이때 Linear model 은 아래와 같이 정의됩니다.

$$E\left(Y_{i} \mid X_{i}\right)=\beta_{0}+\beta_{1} X_{i}$$

- model 에 대한 assumption 하에서, $\beta_1$ 은 Treatment 와 Test 에 대한 차이가 됩니다. 

$$\hat{\beta}_{1}=\overline{Y_{t}}-\overline{Y_{c}}$$

- 이때 각 point 의 $\beta_1$ 추정치에 대한 영향력을 측정하기 위해서 
- linear model setting 을 진행할때에 우리는 DFBETA 를 계산하여서, 각 point 가 얼마나 영향이 있는지를 측정하게 됩니다.

> Note : DFBETA

- DFBETA는 모든 데이터를 사용하여 계산된 독립 변수(예: Main Metric)의 회귀 계수와 삭제된 관측치를 사용하여 계산된 회귀 계수의 차이를 표준 오차로 나눈 값입니다. 
  - 만일 영향력이 큰 변수라면, 이 값이 클 것입니다.
- 통계학자들은 절대 DFBETA 값이 $2/\sqrt{n}$  [16]보다 큰 데이터 점을 조사할 것을 제안합니다. 
- 이떄 page view dataset 에서는, 이러한 규칙을 적용해서 1335개의 데이터를 추려냈었습니다.

![jpg](/assets/images/Stat/159_1.jpg){: .align-center}

- 위 표는 highest absolute DFBETA  를 가지는 data points 값들을 써 넣은것입니다.
- 1등 유저를 보면 Page View 가 3125 나 되며 이 유저의 경우 BFBETA 가 -.028 이나 됩니다.

![jpg](/assets/images/Stat/159_2.jpg){: .align-center}

- 이러한 Outlier 가 실험에 미치는 정도를 알아보기 위해서 위의 표를 봅시다. 
- 위는 Top Influence point ($K(K \leq 20)$) 를 삭제해가면서 T 검정을 수행해 보았습니다. 
- 20개의 특이치만 제거하더라도, 처리 효과의 추정치가 35.3% 변경되는것을 볼 수 있습니다.
- 많은 실험에서, 특이치의 분포는 Control 과 Treatment 그룹간 치우쳐져 있습니다.
  - 예시로 , 일부 웹 크롤러는 Test 버젼과 Control 버젼에 대해서 다르게 작동할 것입니다. 

> ## B. Impact of Outliers on Power of Experiment

- 특이치의 또 다른 영향은 메트릭 분산의 팽창으로서, 이는 결국 실험에서 더 큰 표본 크기를 필요로 하게 됩니다.
- Power Analysis 는 실험 전에 필요한 샘플 사이즈를 정하기 위해서 사용되곤 합니다. 

![jpg](/assets/images/Stat/159_3.jpg){: .align-center}

- 위 표 III는 예제 데이터 세트에서 상위 K개의 영향력 있는 데이터 포인트를 제거할 때 필요한 샘플 크기가 어떻게 변경되는지 보여줍니다. 
  - 이때 필요한 샘플 사이즈 계산은 Effect size : 5% , Type 1 에러 : 0.05 , Type 2 에러 : 0.2 로 고정했습니다.
- 가장 영향력 있는 20개의 데이터 점을 제거하면 합동 분산이 절반 이상 축소됩니다. 
- 그에 따라서 표본 크기 요구사항이 52.5% 감소합니다(54, 096에서 25, 701로).

# [II. OUTLIERS IN ONLINE EXPERIMENTATION](#link){: .btn .btn--primary}{: .align-center}

> ## Introduction 

- 비록 이상치 탐지가 오랫동안 일반적인 관행이었지만, "outlierr"라는 용어는 사실 정확하게 정의되지 않았습니다.
- Outlier 가 정확히 어떤것인지? 에 대해서는, 적용된 Outlier Detection 방법과 , 데이터에 따른 가정에 의존하게 됩니다.  
  - ex : 일반적으로 쓰이는 평균 + 3표준편차 이상을 이상치 취급하는 방법론은 데이터 구조가 Normal 이라는 가정 하에 0.3 percentile 을 쳐내게 됩니다.
- 그러나 일부 Definition은 다양한 유형의 데이터와 방법에 대처할 수 있을 만큼 충분히 일반적인 방법도 있습니다. 
- Hawkins [18]는 특이치를 다른 메커니즘에 의해 생성되었다는 의심을 불러일으킬 정도로 다른 관측치로부터 너무 많이 벗어나는 관측치로 정의했습니다. 
- 이 섹션에서는 일변량 데이터에 대해 일반적으로 사용되는 이상치 탐지 방법을 제시한다. 
- 또한 통계학자가 작성한 특이치에 대한 몇 가지 우수한 책과 리뷰 논문도 있습니다. 

> ## 3 SD Method 

- 3 SD method 는 평균으로부터 3 Standard Deviation 이상 벗어나 있는 지점부터 Outlier 라고 정의하게 됩니다.
- 이는 데이터가 정규분포를 따르는것으로 가정하고, 99.7% 의 영역은 정상 데이터로 가정하고, 0.3% 의 영역을 Outlier 로 정의합니다. 

> ## EDR-ESD identifier

- Distribution Based Method - Outlier Detection Method 의 중심 가정은 Outlier - Generating model 은 target distribution F 와 다른 $$G_1 ... G_k$$ 라는 Distribution 에서 유래되었다고 가정합니다.
  - 이떄 Target Distribution 은 종종 Normal Distribution 이라 가정합니다.
- 이제 특이치 영역에 있는 관측치를 찾아서, 이 영역의 데이터를 Outlier 라 정의하겠습니다.
- 이러한 특이치 영역은 Confidence Coefficient $\alpha$ ($0< \alpha<1 $) 에 대해 Normal Distribution 에 대한 Outlier Region는 아래처럼 정의합니다.

$$\operatorname{out}\left(\alpha, \mu, \sigma^{2}\right)=\left\{x:|x-\mu|>z_{1-\alpha / 2} \sigma\right\}$$

- 이떄 $z_{1-\alpha / 2}$ 는 Standard Normal DIstribution 의 $1-\alpha / 2$ Quantile 입니다.
- 위 식의 의미는. $x$ 가 Outlier가 되려면  $\alpha$ quantile 보다 극단에 위치한다는 것입니다.
- 정리하자면 $x$ is an $\alpha$-outlier with respect to $F$ if $x \in \operatorname{out}\left(\alpha, \mu, \sigma^{2}\right)$.
- 그러면 정상데이터에 속할 확률은 자연스럽게 아래처럼 정해집니다.

$$P\left(x \notin \operatorname{out}\left(\alpha, \mu, \sigma^{2}\right)\right)=1-\alpha$$

- 위와 같은 정의에 따라서 우리는 n개의 샘플에 대해서 ,Outlier region 을 다음과 같이 생성할 수 있습니다. 이때  Outlier Region 을 $$\operatorname{out}\left(\alpha_{n}, \hat{\mu}, \hat{\sigma}^{2}\right)$$ 라고 하면, 

$$\operatorname{out}\left(\alpha_{n}, \hat{\mu}, \hat{\sigma}^{2}\right)=\left\{x:|x-\hat{\mu}|>z_{1-\alpha_{n} / 2} \hat{\sigma}\right\}$$

- 이때 $$\alpha_{n}=1-(1-\alpha)^{\frac{1}{n}}$$ 로 정의됩니다.
- where $\alpha_{n}=1-(1-\alpha)^{\frac{1}{n}}$. Given a sample $X_{N}=$ $\left\{x_{1}, \ldots, x_{n}\right\}$ without outliers, 
  - 하나의 데이터가 Outlier 로 속할 확률이 $$1-(1-\alpha)^{\frac{1}{n}}$$ 이므로, n 개의 데이터가 모두 outlier 에 속하지 않을 확률은 $$((1-\alpha)^{\frac{1}{n}})^{n}$$ = $$1-\alpha$$ 가 됩니다.

 $$P\left(x_{1}, \ldots, x_{n} \notin \operatorname{out}\left(\alpha_{n}, \hat{\mu}, \hat{\sigma}^{2}\right)\right)=1-\alpha$$

- 이 방법론은 ESD (Extreme Studentized Deviate)  identifer 라 불립니다. 
  - since it is related to the extreme studentized deviate test for a single outlier.
- EDR (extreme deviate removal)-ESD method was proposed by Davies and Gather [24], which is employed to deal with masking and swamping effects. The method starts with a reduced sample, and a test based on the ESD identifier is applied at each stage.

> ## Boxplot Outlier

- Boxplot 은 Tukey 에 의해 제시된 방법으로, NOnparametic method 로 outlier 를 정의하는 간단한 방법입니다. 
- 샘플 $$X=\left\{x_{1}, \ldots, x_{n}\right\} $$ 을 생각해봅시다. Boxplot rule 은 아래와 같은 구역을 outlier 라고 정의하게 됩니다.

$$\left.\left\{x: x<Q_{1}-1.5 I Q R \text { or } x>Q_{3}+1.5 I Q R\right)\right\}$$

- 이때 $Q_1$ 과 $Q_3$ 은 lower , upper quantile 입니다. 그리고 IQR 은 Interquantile distance 로서 $$\left(I Q R=Q_{3}-Q_{1}\right)$$ 로 정의됩니다.

> ## Hampel Identifier 

- The Hampel identifier method 는 outliers 를 sample median 과 median absolute deviation (MAD) 을 이용해서 정의합니다. 
- $$M(\cdot)$$ 를 median function 이라고 합시다. 그러면 MAD 는 다음과 같이 정의됩니다. 

$$MAD = M\left(\left|x_{1}-M(X)\right|, \ldots,\left|x_{n}-M(X)\right|\right)$$

- 그러면 Outlier 는 다음과 같은 region 으로 정의됩니다.

$$\left\{x:|x-M(X)|>z_{1-\alpha_{n} / 2} M A D\right\}$$

> ## K-Means 

- K-Means 방법론은 Cluster Analysis 에서 매우 유명한 방법입니다. 
