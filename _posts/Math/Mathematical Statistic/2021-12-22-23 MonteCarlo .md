---
title:  "Monte Carlo"
excerpt: "몬테카를로 방법론"
categories:
  - Mathematical_Statistics
last_modified_at: 2021-11-30

toc: true
toc_label: "Table Of Contents"
toc_icon: "cog"
toc_sticky: true
use_math: true
---

  몬테타를로 방법 알아보긴
{: .notice--warning}

# [MonteCarlo Method](#link){: .btn .btn--primary}{: .align-center}

> ## Introduction

- 여기에서는 특정 분포나 표본으로부터 관측값을 생성하는 방법을 소개하려고 합니다. 이것을 몬테카를 로(Monte Carlo) 생성이라고 합니다.
- 특정한 분포의 pdf 가 주어졌을때, 이 pdf 를 가지는 R.V. 를 generating 하는것은 쉽지 않습니다. 
  - 다행인것은 R과 같은 대부분의 통계 소프트웨어 패키지는 신뢰할 만한 균등분포 생성자를 가지고 있다는 것입니다. (rand)
- 그러므로 여기에서는 우선, Unif $(0,1)$ 를 가지는 Distribution 은 생성 가능하다고 가정하겠습니다.

> Example

- 이산형 분포로부터의 관측값은 균등분포 생성자로 충분하다. 간단한 예로 공정한 육면체 주사위를 던지는 실험을 생각해보자. 
- 만약 주사위를 던진 결과로 $\{1,2\}$ 와 같은 '작은 수가 나오면 $X$ 는 1 이고 그 외에는 $X=0$ 이라고 하자.
-  $X$ 의 평균이 $\mu=1 / 3$ 임을 참고하라. 만약 $U$ 가 균등 $(0,1)$ 분포를 따르면 $X$ 는 다음과 같이 나타낼 수 있다.

$$X= \begin{cases}1 & 0<U \leq 1 / 3 \\ 0 & 1 / 3<U<1\end{cases}$$

> ## Example : Pi

- 그림같이 한 쌍의 숫자 $\left(U_{1}, U_{2}\right)$ 를 단위 정사각형에서 무작위로 선택하는 실험을 생각해보자. 
  - 즉 $U_{1}$ 과 $U_{2}$ 는 $\mathrm{iid}$ 균등 $(0,1)$ 분포를 따른다.
- 각 점이 무작위 로 선택되었으므로 $\left(U_{1}, U_{2}\right)$ 가 단위 원 안에 있을 획률은 $\pi / 4$ 이다. 확률변수 $X$ 가 다음과 같다고 하자.

$$X= \begin{cases}1 & U_{1}^{2}+U_{2}^{2}<1 \\ 0 & \text { 그 외에 }\end{cases}$$

- 그러면 $X$ 의 평균은 $\mu=\pi / 4$ 이다. 
- $\pi$ 를 추정하는 한가지 방 법은 실험을 독립적으로 $n$ 번 실시하여 $X$ 의 확률표본 $X_{1}, X_{2}, \cdots X_{n}$ 을 구하는 것입니다. 
  - 그렇게 된다면 통계량 $4 \bar{X}$ 는 $\pi$ 의 Unbiased Estimator 가 될 수 있습니다.
- 아래 그림은 이 실험의 20 개 실현값을 보여줍니다. 20 개 점 중에서 15 개가 단위 원 안에 있습니다. 따라서 $\pi$ 의 추정값은 $4(15 / 20)=3.00$ 이다. 
  - 이와 같은 Simulation 을 $n$ 에 대해 수행한 결과는 다음과 같습니다.

$$\begin{array}{|c|rrrrr|}
\hline n & 100 & 500 & 1000 & 10,000 & 100,000 \\
4 \bar{x} & 3.24 & 3.072 & 3.132 & 3.138 & 3.13828 \\
1.96 \cdot 4 \sqrt{\bar{x}(1-\bar{x}) / n} & 0.308 & 0.148 & 0.102 & 0.032 & 0.010 \\
\hline
\end{array}$$

![jpg](/assets/images/Stat/131_1.jpg)

- 추정의 오차를 추정하기 위해 이전에서 유도한 대표본 신뢰구간을 이용할 수 있습니다.

$$\left(\widehat{p}-z_{\alpha / 2} \sqrt{\widehat{p}(1-\widehat{p}) / n}, \widehat{p}+z_{\alpha / 2} \sqrt{\widehat{p}(1-\widehat{p}) / n}\right)$$

- 즉 $\pi$ 에 대해 대 응하는 $95 \%$ 신뢰구간은

$$(4 \bar{x}-1.96 \cdot 4 \sqrt{\bar{x}(1-\bar{x}) / n}, 4 \bar{x}+1.96 \cdot 4 \sqrt{\bar{x}(1-\bar{x}) / n})$$

- 표의 마지막 행에 신뢰구간의 오차 부분이 주어져 있다. 모든 5 개 신뢰구간이 $\pi$ 의 참값을 포함하고 있는것을 쉽게 알 수 있습니다.

> ## Theorem 4.8.1 : Generating Distribution

> Theorem

- 확률변수 U가 균등 $(0,1)$ 분포를 따른다고 한다. $F$ 가 연속형 확률변수라면 확률변수 $X=$ $F^{-1}(U)$ 는 분포함수 $F$ 를 갖는다.

> Proof

- 균등분포의 정의로부터 $U$ 가 $u \in(0,1)$ 에 대해 분포함수 $F_{U}(u)=u$ 를 갖는다는 것을 상기하자.
- 이 사실과, $F(x)$ 가 단조증가임을 가정하면 $X$ 의 분포함수는 다음과 같습니다.

$$\begin{aligned}
P[X \leq x] &=P\left[F^{-1}(U) \leq x\right] \\
&=P[U \leq F(x)] \\
&=F(x)
\end{aligned}$$

> Note

- 위의 정리는 단순하지만, 우리에게 시사하는 바가 큽니다. 바로 'inverse Cdf' 만 구할 수 있다면, 우리는 특정한 pdf 를 가지는 pdf 를 generating 할 수 있다는 의미입니다!

> ## Example : Gamma 

- 이 정리를 이용하여 여러 가지 다른 확률변수의 실현값(관측값)을 생성할 수 있습니다. 
- 예를 들어 $X$ 가 $\Gamma(1, \beta)$ 분포를 갖는다고 가정하자. 균등분포 생성자가 있고 $X$ 의 실현값을 생성하려 한다 고 하자. $X$ 의 분포함수는

$$F(x)=1-e^{-x / \beta}, \quad x>0$$

따라서 분포함수의 역함수는

$$F^{-1}(u)=-\beta \log (1-u), \quad 0<u<1$$

- 그러므로 $U$ 가 균등 $(0,1)$ 분포를 따른다면 $X=-\beta \log (1-U)$ 는 $\Gamma(1, \beta)$ 분포를 가지게 됩니다.
- 예를 들어 $\beta=1$ 이고 균등분포 생성자가 다음과 같은 균등분포 관측값의 열을 생성했다고 합시다.

$$0.473,0.858,0.501,0.676,0.240$$

- 그러면 대응하는 지수분포의 관측값은 다음과 같다.

$0.641,1.95,0.696,1.13,0.274$

> ## Example : Montecarlo integral

- 닫혀 있고 한계가 있는 구간 $[a, b]$ 에서 연속인 함수 $g$ 에 대해 적 분 $\int_{a}^{b} g(x) d x$ 를 구하고자 한다고 합시다.
  - 만약 $g$ 의 역 도함수(antiderivative)가 존재하지 않으면 수치적인 적분을 해야 한다. (즉 적분하기가 힘들면 수치적으로 할수밖에 없단는 것이죠)
- 이떄 쓸 수 있는 간단한 수치적 기법이 몬테카를로 방법이다. 적분을 다음과 같이 나타낼 수 있다.

$$\int_{a}^{b} g(x) d x=(b-a) \int_{a}^{b} g(x) \frac{1}{b-a} d x=(b-a) E[g(X)]$$

- 여기서 $X$ 는 균등 $(a, b)$ 분포를 따른다. 
- 그러면 몬테카를로 기법은 균등 $(a, b)$ 분포로부터 크기 $n$ 인 확률표본 $X_{1}, X_{2}, \cdots, X_{n}$ 을 생성하고 $Y_{i}=(b-a) g\left(X_{i}\right)$ 를 계산한다. 
- 그러면 $\bar{Y}$ 는 $\int_{a}^{b} g(x)$ $d x$ 의 Unbiased Estimator 가 됩니다.

> ## Example : Normal 

- THeorem 4.8.1에서 보듯이, 만약 $F_{X}^{-1}(u)$ 를 닫힌 형태로 구할 수 있다면 $\mathrm{cdf}$ 가 $F_{X}$ 인 관측값을 쉽게 생성할 수 있었습니다.
- 하지만 모든 pdf 에 대해서 역 cdf 를 구하기 어려운 상황도 존재합니다. 이것이 가능하지 않은 많은 경우에 관측값을 생성하기 위한 기법들이 개발되었습니다.
- 아래에서는 Normal 분포에 대해서 R.V. 를 생성하는 방법에 대해서 알아보겠습니다.

> Example

- 정규확률변수를 생성하기 위해 $\mathrm{Box}$ 와 $\mathrm{Muller}(1958)$ 는 다음과 같은 과정을 제시했다.
-  $0<y<1$ 에 대해 균등분포에서 추출한 확률표본을 $Y_{1}, Y_{2}$ 라고 하자. $X_{1}$ 과 $X_{2}$ 는 다음과 같이 정의합시다.

$$\begin{aligned}
&X_{1}=\left(-2 \log Y_{1}\right)^{1 / 2} \cos \left(2 \pi Y_{2}\right) \\
&X_{2}=\left(-2 \log Y_{1}\right)^{1 / 2} \sin \left(2 \pi Y_{2}\right)
\end{aligned}$$

- 이 변환은 일대일이며 획률 0 인 $x_{1}=0, x_{2}=0$ 인 집합을 제외하고 $\left\{\left(y_{1}, y_{2}\right): 0<y_{1}<1,0<\right.y_{2}<1$ 를 $\left\{\left(x_{1}, x_{2}\right):-\infty<x_{1}<\infty,-\infty<x_{2}<\infty\right\}$ 로 mapping 하게 됩니다. 이 경우에 역변환은 다음과 같습니다.

$$\begin{aligned}
&y_{1}=\exp \left(-\frac{x_{1}^{2}+x_{2}^{2}}{2}\right) \\
&y_{2}=\frac{1}{2 \pi} \arctan \frac{x_{2}}{x_{1}}
\end{aligned}$$

-  이것은 다음 야코비안을 갖는다.

$$\begin{aligned}
J=&\left|\begin{array}{cc}
\left(-x_{1}\right) \exp \left(-\frac{x_{1}^{2}+x_{2}^{2}}{2}\right) & \left(-x_{2}\right) \exp \left(-\frac{x_{1}^{2}+x_{2}^{2}}{2}\right) \\
\frac{-x_{2} / x_{1}^{2}}{(2 \pi)\left(1+x_{2}^{2} / x_{1}^{2}\right)} & \frac{1 / x_{1}}{(2 \pi)\left(1+x_{2}^{2} / x_{1}^{2}\right)}
\end{array}\right| \\
=& \frac{-\left(1+x_{2}^{2} / x_{1}^{2}\right) \exp \left(-\frac{x_{1}^{2}+x_{2}^{2}}{2}\right)}{(2 \pi)\left(1+x_{2}^{2} / x_{1}^{2}\right)}=\frac{-\exp \left(-\frac{x_{1}^{2}+x_{2}^{2}}{2}\right)}{2 \pi}
\end{aligned}$$

- $Y_{1}$ 과 $Y_{2}$ 의 결합 pdf는 $0<y_{1}<1,0<y_{2}<1$ 일 때 1 이고 그 외에 0 이므로 $X_{1}$ 과 $X_{2}$ 의 결합 $\mathrm{pdf}$ 는 다음과 같습니다.

$$\frac{\exp \left(-\frac{x_{1}^{2}+x_{2}^{2}}{2}\right)}{2 \pi},-\infty<x_{1}<\infty,-\infty<x_{2}<\infty$$

- 즉 $X_{1}$ 과 $X_{2}$ 는 독립이고 표준정규확률변수이다. 
- 가장 일반적으로 이용되는 정규분포 생성자 중 하나는 Marsaglia와 Bray(1964) 알고리즘이라는 위 과정의 한 변형입니다. (여기에서는 생략)

> ## T-test with montecarlo

- 3.4.1절에서 다룬 오염된 정규분포에서의 관측값은 정규분포 생성자와 균등분포 생성자를 이 용하여 쉽게 구할 수 있다. 
  - 기저분포가 오염된 정규분포일 때 $t$-점정의 유의수준을 몬테카를로를 이용하여 추정해 봅시다.

> Example

- $X$ 가 평균 $\mu$ 인 확률변수일 때 다음 가설을 생각해보자.

$$H_{0}: \mu=0, \quad H_{1}: \mu>0$$

- 이 검정을 $X$ 의 분포에서 추출한 크기 $n=20$ 인 표본에 근거하여 결정한다면 $t$-검정을 이용함으 로써 기각 규칙은 다음과 같다.

$$t>t_{0.05,19}=1.729 \text { 이면 } H_{0}: \mu=0 \text { 기각, } H_{1}: \mu>0 \text { 채택 }$$

- 여기서 $t=\bar{x} /(s / \sqrt{20})$ 이고 $\bar{x}$ 와 $s$ 는 각각 표본평균과 표본표준편차이다.만약 $X$ 가 정규분포를 따르면 이 검정은 수준이 $0.05$ 이다. 
  - 그러나 $X$ 가 정규분포를 따르지 않으면 어떨까? 특히 이 예제에서 $X$가 식 $(3.4 .17)$ 에 주어진 것과 같이 $\epsilon=0.25, \sigma_{c}=25$ 인 오염된 정규분포를 따른다고 합시다.
- 즉 관측값의 $75 \%$ 는 표준정규분포로부터 생성되고 나머지 $25 \%$ 는 평균 0 이고 표준편차 25 인 정규분포로부터 생성된다. 
  - 따라서 $X$ 의 평균은 0 이므로 $H_{0}$ 은 참이다. 
- 검정의 정확한 유의수준을 구하기는 매우 복잡할 것이다.
  - $X$ 가 이러한 오염된 정규분포를 따를 때 $t$ 의 분포를 구해야 한다. 
- 대안으로 모의실험을 이용하여 수준(그리고 추정의 오차)을 추정한다. 모의실험의 수를 $N$ 이라고 하자. 다음 알고리즘에 모의실험 단계를 제시했다.

1. $k=1, I=0$ 이라고 한다.
2. $X$ 의 분포로부터 크기 20 인 확률표본을 생성한다.
3. 이 표본에 근거하여 검정 통계량 $t$ 를 계산한다.
$4 . t>1.729$ 이면 $I$ 를 1 만큼 증가시킨다.
5. $k=N$ 이면 6 단계로 가고, 아니면 $k$ 에 1을 더하고 2단계로 간다.
5. $\widehat{\alpha}=I / N$ 를 계산하고 근사 오차 $=1.96 \sqrt{\widehat{\alpha}(1-\widehat{\alpha}) / N}$ 이라고 한다.

- $\widehat{\alpha}$ 은 $\alpha$ 를 모의실험한 추정값이고 $\alpha$ 에 대한 신뢰구간 폭의 절반은 추정에서의 오차에 대한 추정 값이다.
- . 이것을 $N=10,000$ 번 돌려 다음 결과를 얻 었다.

$$\begin{array}{|c|c|c|c|}
\hline \text { 모의실험 수 } & \text { 실험에서의 } \widehat{\alpha} & \text { 오차 } & \alpha \text { 에 대한 } 95 \% \text { CI } \\
\hline 10,000 & 0.0412 & 0.0039 & (0.0373,0.0451) \\
\hline
\end{array}$$

- 이 결과를 기반으로, 이와 같은 오염된 정규분포에서 표본이 추출되었다면 $t$-검정은 보수적인것 처럼 보이는것을 알 수 있습니다.

# [채택, 기각 알고리즘](#link){: .btn .btn--primary}{: .alig-center}

- 이 절에서는 역 cdf(inverse cdf)를 닫힌 형식으로 구할 수 없는 확률변수에 대한 모의실험에서 이용할 수 있는 채택-기각(accept-reject) 과정을 전개한다.

> Theorem

- pdf $f(x)$ 를 가진 연속형 확률변수를 $X$ 라고 하자. 여기서는 이 pdf를 목표(target) pdf라고 한다.
-  pdf $g(x)$ 를 가진 확률변수 $Y$ 의 관측값을 생성하는 것이 상대적으로 쉽고, 어떤 상수 $M$ 에 대해 다음을 갖는다고 하자.

$$f(x) \leq M g(x), \quad-\infty<x<\infty$$

- $g(x)$ 를 도구(instrumental) pdf라고 한다. 명확하게 하기 위해 채택-기각 과정을 알고리즘으로 정리한다.
- 알고리즘 $4.8 .1$ [채택-기각 알고리즘]
- $f(x)$ 를 pdf라고 하자. $Y$ 가 $\operatorname{pdf} g(y)$ 를 가진 확률변수이고, $U$ 가 균등 $(0,1)$ 분포를 따르는 확률 변수이며, $Y$ 와 $U$ 가 서로 독립이고, 식 $$f(x) \leq M g(x)$$  가 성립한다고 하자. 다음 알고리즘은 $\mathrm{pdf} f(x)$ 를 가진 확률변수 $X$ 를 생성한다.

1. $Y$ 와 $U$ 를 생성한다.
1. $U \leq \frac{f(Y)}{M g(Y)}$ 이면 $X=Y$, 아니면 1 단계로 돌아간다.
3. $X$ 는 $\operatorname{pdf} f(x)$ 를 갖는다.

> ## Proof

- 이 알고리즘의 타당성에 대한 증명: $-\infty<x<\infty$ 라고 하면

$$\begin{aligned}
P[X \leq x] &=P\left[Y \leq x \mid U \leq \frac{f(Y)}{M g(Y)}\right] \\
&=\frac{P\left[Y \leq x, U \leq \frac{f(Y)}{M g(Y)}\right]}{P\left[U \leq \frac{f(Y)}{M g(Y)}\right]} \\
&=\frac{\int_{-\infty}^{x}\left[\int_{0}^{f(y) / M g(y)} d u\right] g(y) d y}{\int_{-\infty}^{\infty}\left[\int_{0}^{f(y) / M g(y)} d u\right] g(y) d y} \\
&=\frac{\int_{-\infty}^{x} \frac{f(y)}{M g(y)} g(y) d y}{\int_{-\infty}^{\infty} \frac{f(y)}{M g(y)} g(y) d y} \\
&=\int_{-\infty}^{x} f(y) d y
\end{aligned}$$

- 따라서 양쪽을 미분하면 $X$ 의 $\mathrm{pdf}$ 가 $f(x)$ 임을 알게 된다.

> ## Note

- 주목할 만한 두 가지 사실이 있습니다.

> 첫째, 알고리즘에서 채택의 확률은 $1 / M$ 이다. 

- 이것은 정리의 증명을 도출하는 과정에서 알 수 있습ㄴ다. 도출 과정에서 다음 식을 보여주는 분모를 한번 생각 해보자.

$$P\left[U \leq \frac{f(Y)}{M g(Y)}\right]=\frac{1}{M}$$

- 따라서 알고리즘의 효율성을 위해 $M$ 이 가능한 한 작기를 바란다. 

> 둘째, $\mathrm{pdf} f(x)$ 와 $g(x)$ 의 정규화 상수(normalizing constant)는 무시할 수 있다. 

- 예를 들어 상수 $c$ 와 $k$ 에 대해 $f(x)=k h(x)$ 이고 $g(x)=\operatorname{ct}(x)$ 이면 다음 규칙을 사용할 수 있다.

$$h(x) \leq M_{2} t(x), \quad-\infty<x<\infty$$

- 그리고 알고리즘의 2 단계에 있는 비율을 $U \leq h(Y) /\left[M_{2} t(Y)\right]$ 로 변경할 수 있다. 그러면 $M_{2}=$ $\mathrm{c} M / k$ 일 때 식 $(4.8 .9)$ 가 성립하는 경우에 한하여 식 $(4.8 .5)$ 가 성립한다는 결과가 직접적으로 뒤따른다. 이는 채택-기각 알고리즘의 사용을 종종 단순화한다.
- 다음으로 채택-기각 알고리즘의 두 가지 예제를 제시한다. 첫 번째 예제에서는 도구 확률변수 Y가 코시 분포를 가진 정규 생성자를 제공한다. 두 번째 예제에서는 모든 감마분포가 생성되는 방법을 보여준다.

> ## Exmaple 

- $X$  는 pdf가 $\phi(x)=(2 \pi)^{-1 / 2} \exp \left(-x^{2}/2\right)$   인 정규분포확률변수이고 Y 는 pdf 가 $g(x)=\pi^{-1}\left(1+x^{2}\right)^{-1}$ 인 코시 분포를 갖는다고 가정합시다. 
- 연습문제 4.8.9 에서 보듯이 코시분포는 역 cdf 가 알려진 함수이기 떄문에 쉽게 시뮬레이션 할 수 있습니다. 정규화 상수를 무시하면 경계에 대한 비율은 다음과 같습니다.

$$\frac{f(x)}{g(x)} \propto\left(1+x^{2}\right) \exp \left\{-x^{2} / 2\right\}, \quad-\infty<x<\infty$$

- 연습문제 $4.8 .17$ 에서 알 수 있듯이 이 비율의 도함수는 $-x \exp \left\{-x^{2} / 2\right\}\left(x^{2}-1\right)$ 이고, $\pm 1$ 에서 임곗값을 갖는다. 이 값에서 위 식의  최댓값이 되므로 다음과 같이 계산된다.

$$\left(1+x^{2}\right) \exp \left\{-x^{2} / 2\right\} \leq 2 \exp \{-1 / 2\}=1.213$$

- 그래서 $M_{2}=1.213$ 이다. 따라서 위의 논의로부터 $M=(\pi / \sqrt{2 \pi}) 1.213=1.520$ 이고, 알고리즘 의 채택률은 $1 / M=0.6577$ 이다.

---

**Reference**

- Hoggs Introduction to Mathematical Statistics 7ed



