---
title:  "Geometric Distribution"
excerpt: "기하분포에 대해서 알아보자"
categories:
  - Mathematical_Distribution
last_modified_at: 2021-11-24

toc: true
toc_label: "Table Of Contents"
toc_icon: "cog"
toc_sticky: true
use_math: true

---

 Binomial Distribution
{: .notice--warning}

# [Geometric Distribution](#link){: .btn .btn--primary}{: .align-center}

> ## Definition

> Definition

**기하 분포**(geometric distribution)는 Discrete Distribution 중의 하나로, 다음 두 가지 정의가 있습니다.

- Bernoulli Trials 에서 처음 성공까지 시도한 횟수 X의 분포. Support 는 {1, 2, 3...}이다.
- Bernoulli Trials 처음 성공할 때까지 실패한 횟수 즉 Y=X-1의 분포 Support는 {0, 1, 2, ...}이다.

보통 편의에 따라 둘 중 하나를 선택해 이용하며, 기하 분포를 언급할 때는 어느 정의를 이용하는지 분명히 하는 것이 좋다. 대개의 경우 X의 분포를 가르킵니다. 그러므로 저희도 X (성공까지 시도한 횟수) 로 알아보겠습니다.

# [Elementary Properties](#link){: .btn .btn--primary}{: .align-center}

$$\begin{array}{|l|l|}
\hline \text { Parameters } & \begin{array}{l}
0<p \leq 1 \text { success probability } \\
\text { (real) }
\end{array} \\
\hline \text { Support } & k \text { trials where } k \in\{1,2,3, \ldots\} \\
\hline \text { PMF } & (1-p)^{k-1} p \\
\hline \text { CDF } & 1-(1-p)^{k} \\
\hline \text { Mean } & \frac{1}{p} \\
\hline
\hline \text { Median } & {\left[\frac{-1}{\log _{2}(1-p)}\right]} \\
& \begin{array}{l}
\text { (not unique if }-1 / \log _{2}(1-p) \text { is } \\
\text { an integer) }
\end{array} \\
\hline \text { Mode } & 1 \\
\hline \text { Variance } & \frac{1-p}{p^{2}} \\
\hline \text { Skewness } & \frac{2-p}{\sqrt{1-p}} \\
\hline \begin{array}{l}
\text { Ex. } \\
\text { kurtosis }
\end{array} & 6+\frac{p^{2}}{1-p} \\
\hline \text { Entropy } & \frac{-(1-p) \log _{2}(1-p)-p \log _{2} p}{p} \\
\hline \text { MGF } & \frac{p e^{t}}{1-(1-p) e^{i t}} \\
\hline \text { CF } & \begin{array}{l}
1-(1-p) e^{t} \\
\text { for } t<-\ln (1-p)
\end{array} \\
\hline
\end{array}$$

> ## proof : E(X) = p

> Proof

Since $X$ obeys the geometric distribution, , the expectation value is

$$\begin{aligned}
E(X) &=\sum_{k=1}^{\infty} k \operatorname{Pr}(X=k) \\
&=\sum_{k=1}^{\infty} k p(1-p)^{k-1} \\
&=p \sum_{k=1}^{\infty} k(1-p)^{k-1} \ \ \ \  (1)
\end{aligned}$$

To find the sum in the right-hand side, we use Taylor expansion of function $1 /(1-x)$

$$\begin{aligned}
\frac{1}{1-x} &=1+x+x^{2}+\cdots \\
&=\sum_{k=0}^{\infty} x^{k}
\end{aligned}$$

The derivative of the left-hand side is

$$\left(\frac{1}{(1-x)}\right)^{\prime}=\frac{1}{(1-x)^{2}}$$

and that of the right-hand side is

$$\left(\sum_{k=0}^{\infty} x^{k}\right)^{\prime}=\sum_{k=1}^{\infty} k x^{k-1}$$

We thus have

$$\frac{1}{(1-x)^{2}}=\sum_{k=1}^{\infty} k x^{k-1}$$

If we put $x=1-p$, this equation becomes

$$\frac{1}{p^{2}}=\sum_{k=1}^{\infty} k(1-p)^{k-1}$$

Substituting this into $(1)$, we obtain

$$E(X)=p \frac{1}{p^{2}}=\frac{1}{p}$$

> ## Proof : V(X) = $\frac{1-p}{p^{2}}$

> Proof

In general, the variance is the difference between the expectation value of the square and the square of the expectation value, i.e.,

$$V(X)=E\left(X^{2}\right)-E(X)^{2}$$

Since the expectation value is $E(X)=\frac{1}{p}$, we have

$$V(X)=E\left(X^{2}\right)-\frac{1}{p^{2}} \ \ \ \cdots (1)$$

To obtain the variance, we thus need to derive the expectation of $X^{2}$. The expectation value of $X^{2}$ with the geometric distribution is

$$\begin{aligned}
E\left(X^{2}\right) &=\sum_{k=1}^{\infty} k^{2} \operatorname{Pr}(X=k) \\
&=\sum_{k=1}^{\infty} k^{2} p(1-p)^{k-1} \\
&=p \sum_{k=1}^{\infty} k^{2}(1-p)^{k-1} \ \ \cdots (2)
\end{aligned}$$

In order to obtain the sum in the right-hand side, we focus on the Taylor expansion of $1 /(1-x)$

$$\begin{aligned}
\frac{1}{1-x} &=1+x+x^{2}+\cdots \\
&=\sum_{k=0}^{\infty} x^{k}
\end{aligned}$$

and differentiate both sides:

$$\frac{1}{(1-x)^{2}}=\sum_{k=1}^{\infty} k x^{k-1}$$

We multiply the both sides by $\mathrm{x}$,

$$\frac{x}{(1-x)^{2}}=\sum_{k=1}^{\infty} k x^{k}$$

and differentiate both sides:

$$\frac{1+x}{(1-x)^{3}}=\sum_{k=1}^{\infty} k^{2} x^{k-1}$$

We put $x=1-p$

$$\frac{2-p}{p^{3}}=\sum_{k=1}^{\infty} k^{2}(1-p)^{k-1}$$

and substitute this into $(2)$,

$$E\left(X^{2}\right)=p \frac{2-p}{p^{3}}=\frac{2-p}{p^{2}}$$

From this and $(1)$, we obtain

$$V(X)=\frac{2-p}{p^{2}}-\frac{1}{p^{2}}=\frac{1-p}{p^{2}}$$

# [More Properties](#link){: .btn .btn--primary}{: .align-center}

> ## Memoryless properties

> Theorem

A geometric random variable $X$ has the memoryless property if for all nonnegative integers $s$ and $t$

$$P(X \geq s+t \mid X \geq t)=P(X \geq s)$$

or, equivalently

$$P(X \geq s+t)=P(X \geq s) P(X \geq t)$$

> Proof

The probability mass function for a geometric random variable $X$ is

$$f(x)=p(1-p)^{x} \quad x=0,1,2, \ldots$$

The probability that $X$ is greater than or equal to $x$ is

$$P(X \geq x)=(1-p)^{x} \quad x=0,1,2, \ldots$$

So the conditional probability of interest is

$$\begin{aligned}
P(X \geq s+t \mid X \geq t) &=\frac{P(X \geq s+t, X \geq t)}{P(X \geq t)} \\
&=\frac{P(X \geq s+t)}{P(X \geq t)} \\
&=\frac{(1-p)^{s+t}}{(1-p)^{t}} \\
&=(1-p)^{s} \\
&=P(X \geq s)
\end{aligned}$$

which proves the memoryless property.

> Intuition

통계적인 independence 는 $\operatorname{Pr}(X \mid I)=\operatorname{Pr}(X)$ 를 의미합니다. 즉 이는  information $I$ 는 X 에 대해서 아무런 정보를 제공하지 못함을 의미합니다. 이를 숙지하고 memoryless property 를 살펴볼까요?

$$P(X \geq s+t \mid X \geq t)=P(X \geq s)$$

위에서, X 는 '성공할때까지 시도한 횟수' 라는것을 기억합시다. 즉 과거에 얼마나 실패했던지 간에, 미래에 얼마나 시도할 횟수에는 아무런 영향이 없다는 것입니다. 이를  하면 다음과 같습니다. 

$$\operatorname{Pr}\left(X_{t+1} \mid X_{t}, X_{t-1}, X_{t-2}, \ldots\right)=\operatorname{Pr}\left(X_{t+1}\right)$$

즉 이전의 동전이 TTTTTTTTTTTTTT 가 나왔다고 해서, 그 뒤의 동전이 T 가 나올 확률은 같다는 것입니다. 이는 직관과는 위배될 수 있습니다. (왜냐하면 T 가 많이 나왔으니까 , 이 동전은 그 이후에도 T 가 많이 나올거라 예상할 수 있으니까요) 하지만 여기서 중요한것은 우리가 이 모델을 정의할때에 'Independent 한 Ber(p) 의 수행을 반복할때에 T 가 나올때까지의 수행 횟수 = X ' 로 정의했다는것을 명십합시다. 즉 이전의 히스토리가 T 던, TTTT...T 건 p(앞면이 나올 횟수) 는 변하지 않는 Constant 값입니다. 즉 앞의 정보를 아무리 알아봤자 p 에는 아무런 영향을 미칠 수 없으므로 Memoryless 라고 하는것입니다.

---

**reference**

- Hoggs Introduction to Mathematical Statistics 7ed
- <http://www.math.wm.edu/~leemis/chart/UDR/PDFs/GeometricF.pdf>
- <https://semath.info/src/st-geometric-distribution.html>
- <https://www.quora.com/Why-is-geometric-distribution-memoryless-but-binomial-isnt-How-can-I-understand-it-intuitively-beyond-the-formula-proofs>
- <https://www.quora.com/What-is-an-intuitive-explanation-of-the-memoryless-property>







