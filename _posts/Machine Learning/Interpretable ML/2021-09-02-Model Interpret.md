---
title:  "What is Interpretability?"
excerpt: "해석력은 어떤것을 의미하는가?"
categories:
  - Interpretable_ML
last_modified_at: 2021-09-01

toc: true
toc_label: "Table Of Contents"
toc_icon: "cog"
toc_sticky: true

use_math: true
---

# [Intro](#link){: .btn .btn--primary} 

- 기계학습 모델을 해석할떄에, 이것을 사람이 어떻게 해석할 수 있는지에 대해서는 많은 방법이 존재합니다. 
- 그 이유는 어떤것을 기준으로 하는지에 따라서 모델을 해석할 수 있는 여부가 달라지기 떄문입니다.

# [해석방법 : Intrinsic vs Post-hoc](#link){: .btn .btn--primary} 

> ## 사전(Intrinsic) 해석

- 모델을 단순하게 만듦으로서, 모델을 사전 해석할 수 있습니다.  즉 모델링 그 자체로 해석이 가능합니다.
- 대표적으로는 Linear regression 이 가능합니다. 
  - 변수의 크기는, 곧 그 변수의 중요도가 될 수 있습니다
  - 또한 p-value 를 통해서 그 변수가 얼마나 유의한지도 살펴볼 수 있습니다.
- 주로 모델의 내재적 구조 정보를 이용하여 분석하게 됩니다.
- 사전 해석법은 비교적 모델이 단순한 linear regression / Disicion Tree 등에 이용됩니다.. 

> ## 사후(Post-hog) 해석

- 사후 해석법은 모델의 종류에 상관 없이, 그 모델의 Input 과 Output 을 살펴보면서 해석하게 됩니다.
- 사후 해석법은 모든 모델에 대해서 적용이 가능합니다.

# [해석 방법 : Global vs Local](#link){: .btn .btn--primary} 

- 모델을 어떤 범위에서 해석하는지에 따라 해석 방법을 다르게 할 수 있습니다. 

> ## Local 해석

- 각 데이터 Point 마다 해석을 하는 방법은 Local 해석이라고 합니다. 
- 예시로 , '키 180cm , 몸무게 100kg 인 경우 소득을 30만달러라고 예측했는데 그 이유가 궁금해!' 같은 경우에 사용됩니다. 
- 이런 Local 해석은 전체 모델의 해석 결과보다 '특정한 Point' 에 집중하여 해석하기 떄문에, 특정 데이터 해석에 대해서는 Global 해석보다 정확합니다. 

> ## Global 해석

- 전체 데이터를 아우르는 해석입니다.
- 예를 들어서 대체로 이 모델에서 어떤 변수가 어떤 작용을 하였는지를 나타내는 설명입니다. 
- 데이터를 전반적으로 이해하는데에는 도움을 주지만, 특정 경우에 대해서는(Local) 설명력이 안좋을 수 있습니다.

# [해석력의  평가기준](#link){: .btn .btn--primary} 

- 위에서 우리는 해석 방법에 따라서 여러지 '해석' 이 있음을 알았습니다.
- 우리는 과연 특정한 모델에서 여러가지 '해석' 력을 어떻게 평가할 수 있을까요? 

> ## 알고리즘 투명성(Algorithm Transparency)

> 이 알고리즘은 어떻게 모델을 생성할까?

- 알고리즘 투명성은, 작동 원리를 단순히 알 수 있다는것이 아니라, 이 모델이 현제 어떻게 예측하고 있고 어떤 흐름으로 각 변수가 영향을 주는지를 안다는 것입니다. 
- DNN 모델의 경우, 역전파 알고리즘으로 어떻게 모델이 학습하는지는 알 수 있지만 수백만개의 노드가 어떤 영향으로 어떻게 예측이 이루어지는지를 모두 알기는 어려울 것입니다.
  - 이러한 경우 알고리즘이 불투명하다고 합니다.
- linear regression 의 경우 최소 제곱법이라는 Fitting 원리를 이해할 수 있으며 어떻게 예측이 되는지도 모두 알 수 있습니다. 

> ##  전반적 모델 해석력(Global)

> 학습된 모델은 어떻게 예측을 할 수 있는걸까?

![jpg](/assets/images/ML/4_1.png)

- 모델의 전체를 이해할 수 있다면, 이 모델은 해석가능하다고 할 수 있습니다. 
- 이 단계에서 해석력은 모델의 특징 / Weight / 모델의 구조 / 데티어의 구조 등 전체적인 관점에서 모델이 어떻게 결정하는지에 대해서 이해하는것을 말합니다.
- 현실세계에서는 변수가 많고 Weight 도 매우 많아서, 모델을 전반적으로 이해하는것은 매우 어렵습니다.

> ## 모듈 수준의 전반적 모델 해석력(Global)

> 어떻게 모델의 일부가 전반적인 예측에 영향을 줄 수 있을까?

- 우리는 많은 Weight 들을 기억하고, 모델이 어떠한 기준으로 현실을 바라보고 , 예측하고 있는지를 이해하기란 어렵습니다.
  - 단순 Linear regression 에서도 상호작용을 고려하다보면 전반적인 모델 해석은 엄청나게 어렵습니다. 
- 하지만 '모델의 전반적 이해' 가 아니라, 하나의 가중치(하나의 모듈)만 살펴본다면 어떨까요? 
  - 예를 들어서 Linear regression 에서 , 다양한 사람들의 특성을 이용하여 소득을 예측할떄 '키' 라는 Weight 만 바라봅시다.
  - 이 경우에 2.5 라는 Weight 를 가지고 있다면, 1cm 당 소득에 기여하는 정도가 2.5 라고 이해할 수 있습니다. 
  - 또는 , Decision Tree 에서 하나의 분기 노드만 살펴볼 수도 있습니다.
- 물론 모델을 전체적으로 바라보는것보다는 부분을 이해하는게 좀 더 쉬워보입니다만, 이 역시 다양한 Issue 가 존재합니다.
  - Linear regression 에서의 Weight 는 상관관계가 존재하여 독립적으로 해석하기가 쉽지 않습니다.

> ## 단일 예측에 대한 지역적 해석력(Local)

> 왜 이 모델은 이 샘플에 대해서 이런 예측을 할까?

- 단일 인스턴스(샘플) 을 확대하여 이에 대해 모델이 예측하는것을 살펴보고 , 그 이유를 설명하는 경우입니다.
- 개별적인 예측만 살펴보는것은 전체 예측하는것보다 쉽게 해석이 가능합니다. 
- 이러한 지역적 예측은, 각 변수들간의 관계가 어렵지 않을것입니다.
- 예를 들어서, 집에대한 가격 예측을 한다고 합시다. 이러한 예측은 엄청난 변수가 얽혀있어서 예측에 대한 전반적인 해석이 어렵습니다. 
  - 하지만 '7평인 내 집' 으로만 제한한다면 어떨까요? 자연스럽게  대학생 / 저소득층으로 그 표본이 제한될 것이고 해석이 좀 더 쉬워질것입니다.
- 즉 Local 해석은 좀 더 Global 해석보다 좀 더 정확할 수 있습니다.

> ## 그룹 예측에 대한 지역적 해석력(Local) 

> 왜 이 모델은 샘플 그룹에 대해서 이런 예측을 할까? 

- 이는 하나의 샘플에 대해서만 살펴보는게 아니라, 특정한 그룹에 대해서 모델의 예측을 해석하는것입니다.
- 위의 예시(집값예측) 에서, 10평 이하인 그룹으로만 제한할 경우 저소득층으로 제한되어서그 해석이 좀 더 쉬워질 수 있습니다.
- 이 해석 또한 Global 한 해석보다는 훨씬 쉬울것입니다. 

# [해석력을 어떻게 Measure할까?](#link){: .btn .btn--primary} 

- 해석력에 대한 다양한 논의가 있었습니다만 아직 실질적인 합의는 이루어지지 않은 상황입니다.
- 또한 어떻게 이를 측정해야하는지도 명확하지 않은 상황입니다. 
- 이에 대한 연구가 진행중이며, (Doshi-Velex and Kim, 2017) 에 따르면 해석력 평가를 위해 크게 세가지 방법으로 나타낼 수 있다고 합니다.

> ## 적용 수준의 평가(실제작업)

- 완성된 제품에 설명서를 첨부하여 최종 사용자가 이를 사용하는 방식입니다. 

**[ Example ]** <br>X-ray에서 부상자의 골절을 찾아 표시하는 기계학습 기능을 갖춘 골절 감지 소프트웨어가 있다고 합시다. 전문 의사는 적용 수준에서 골절 검출 소프트웨어를 직접 테스트하여 모델을 평가합니다. 전문 의사와 같이 합리적인 수준으로(또는 그 이상으로) 결정을 높은 수준으로 예측하고 / 해석할 수 있는지를 평가하게 됩니다.
{: .notice}

> ## 인적 수준 평가(단순작업)

- 이 평가는 단순화된 적용 수준 평가라 할 수 있습니다. 
- 차이점은 이러한 평가가 특정 분야의 전문가에 의해 수행되는 것이 아니라 일반인을 대상으로 수행된다는 점입니다. 
- 이는 실험을 더 저렴하게 만들고(특히 방사선 전문의를 활용하는 것보다 인건비가 절약될 수 있을 것입니다.) 더 많은 테스터를 찾는 것이 더 쉽습니다. 
- 예를 들어 사용자에게 다양한 모델이 도출한 다른 설명서(해석)을 보여주고 사용자가 가장 좋은 설명을 선택하는 경우라 할 수 있습니다.
  - 가장 많은 선택을 지닌 경우가 해석력이 좋은 모델일것입니다.

> ## 기능 수준의 평가(대리작업)

- 이 평가는 사람을 필요로 하지 않습니다. 이는 사용된 모델의 수준이 이미 인적 수준 평가에서 다른 사람에 의해 평가 되었을 때 가장 잘 작동합니다. 
- 예를 들어 최종 사용자가 의사 결정 트리를 이해하고 있다는 것으로 들 수 있겠습니다. 
  - 이러한 경우 트리의 깊이가 바로 해석력과 관련있게 됩니다. 즉 트리가 짧으면 설명성 점수가 더 좋습니다.  
  - 트리의 예측 성능이 여전히 양호하고 큰 트리에 비해 너무 감소하지 않는다는 제약조건을 추가한다면, 이러한 기능 수준(모델 수준) 의 평가가 좀 더 합리적인 수준 평가라 볼 수 있겠습니다.
