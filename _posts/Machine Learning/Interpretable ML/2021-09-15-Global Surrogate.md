---
title:  "Global Surrogate"
excerpt: "블랙박스 모델의 예측을 학습하는 모델"
categories:
  - Interpretable_ML
last_modified_at: 2021-09-15

toc: true
toc_label: "Table Of Contents"
toc_icon: "cog"
toc_sticky: true

use_math: true
---

 전역 대체모델(Global surrogate model)은 블랙박스 모델의 예측에 근사하게 학습된 해석할 수 있는 모델입니다. 대체 모델을 해석함으로서 블랙박스 모델에 대한 결과를 도출할 수 있습니다. 즉 좀 더 쉬운 모델을 이용해 예측을 근사하는 모델을 만드는것입니다.
{: .notice--warning}

# [Global surrogate model](#link){: .btn .btn--primary}{: .align-center}

> ## Theory : 어떻게 작동하나

-  대체모델은 공학에서도 사용됩니다. 관심 대상의 결과물을 도출하기에 비싸거나, 시간이 많이 걸리거나, 측정하기 어려운 경우(복잡한 컴퓨터 시뮬레이션과 같은 경우), 그 결과물에 대한 값싸고 빠른 대체모델을 대신 사용할 수 있습니다. 
- 엔지니어링에 사용되는 대체모델과 해석할 수 있는 기계학습에 사용되는 대체모델의 차이는 기본 모델이(시뮬레이션이 아닌) 기계학습 모델이며 대체모델은 반드시 해석할 수 있어야 한다는 점입니다. (해석할 수 있는) 
- 대체모델의 목적은 가능한 한 정확하게 기반 모델의 예측값을 근사하게 하고 동시에 해석할 수 있도록 하는 것입니다. 
- 대체모델의 아이디어는 다음과 같은 또다른 이름들에서 예측할 수 있습니다. 근사 모델(Approximation model), 메타 모델(Metamodel), 반응 포면 모델(Response surface model), 에뮬레이터(Emulator)와 같이 말이지요.
- 사실은 대체모델을 이해하는데 빌요한 이론은 많지 않습니다. 
- 함수 g가 해석할 수 있는 제약조건 하에 가능한 한 대체모델 예측 함수 g와 근접하게 블랙박스 예측 함수 f의 근사값을 구하고자 합니다. 함수 g의 경우 해석할 수 있는 모델을 사용할 수 있습니다.

![jpg](/assets/images/ML/5_1.png)

- 예를 들면  g는 위와 같은 선형모델이 될 수 있습니다.

![jpg](/assets/images/ML/5_2.png)

- 또는 위처럼 의사결정나무가 될 수 있습니다.
- 대체모델을 학습시키는 것은 블랙박스 모델 내부 동작에 대한 정보가 필요없고 데이터에 대한 접근과 예측 가능성만 필요하므로 모델 불특정성 방법(model-agnostic method)입니다.
-  만약 기초적인 기계학습 모델을 다른 것으로 교체한다면, 여전히 대체 방법을 사용할 수 있습니다. 블랙박스 모델 유형과 대체 모델 유형의 선택은 분리시킬 수 있습니다.

> ## Fitting : g 를 어떻게 찾지?

- 다음과 같은 단계를 수행하여 대체 모델을 얻을 수 있습니다.

> Fitting 과정

1.  데이터셋 X을 선택합니다. 이는 블랙박스 모델을 학습시키는데 사용된 것과 동일한 데이터셋 또는 동일한 분포의 새로운 데이터셋일 수 있습니다.  응용 프로그램에 따라 데이터의 부분집합이나 격자 구조의 점 구조의 데이터를 선택할 수도 있습니다.
2.  선택한 데이터셋 X에 대하여 블랙박스 모델의 예측값을 얻습니다.
3.  해석할 수 있는 모델 유형(선형 모델, 의사결정 트리 등)을 선택합니다.
4.  데이터셋 X와 예상값으로 해석할 수 있는 모델을 학습시킵니다.
5.  축하합니다! 여러분께서는 대체 모델을 만들게 되었습니다!
6.  블랙박스 모델의 예측값을 대체모델이 얼마나 잘 복제하는지 측정합니다.
7.  대체모델을 해석합니다.

- 위 과정에서 약간의 추가 단계가 있거나 약간 다른 대체모델에 대한 접근법을 찾을 수 있지만, 일반적인 생각은 보통 여기서 설명한 것과 같습니다.

> Fitting 기준

- 대체모델이 블랙박스 모델을 얼마나 잘 복제하는지 측정해보는 방법 중 하나는 R-제곱(R-suared) 측정값입니다. 식은 아래와 같습니다.

![jpg](/assets/images/ML/5_4.png)

- 여기서 $\hat{y_*}^{(i)}$는 대체 모델의 i번째 인스턴스의 예상값이고,  $\hat{y}^{(i)}$는 블랙박스 모델의 예측값이며$\bar{\hat{y}}$는 블랙박스 모델 예측값의 평균을 나타냅니다. 
-  기본 블랙박스 모델의 모델 성능, 즉 실제 결과를 예측하는데 얼마나 좋은 성능을 발휘하는지 등에 대해서는 언급하지 않았음에 유의하길 바랍니다. 
- 블랙박스 모델의 성능은 대체모델을 학습시키는 역할을 하지 않습니다. 대체모델의 해석은 실제 세계에 관한 것이 아니라 모델에 관한 주장을 하기 때문에 여전히 유효합니다. 
- 그러나 물론 블랙박스 모델이 좋지 않으면 대체모델의 해석도 관계가 없어지는데, 그 이유는 블랙박스 모델 자체가 연관성이 없기 때문입니다.

> ## 지역 가중치

-  또한 원본 데이터의 부분집합을 기반으로 한 대체모델을 만들거나 인스턴스의 가중치를 재조정할 수도 있습니다. 
- 이런 식으로 대체모델 입력의 분포를 바꾸는데, 이는 해석의 초점을 바꾸게됩니다(그러면 이는 더이상 정말로 전역적이지 않게됩니다). 
- 데이터의 특정 인스턴스에 의해 데이터의 지역 가중치를 부여하면(선택된 인스턴스로부터 그 인스턴스가 더 가까울스록 가중치는 더 커짐) 인스턴스들의 개별 예측을 설명할 수 있는 지역 대체모델을 얻게 됩니다. 
- 이는 다음에 지역 모델에 대해 자세히 다루어보도록 하겠습니다.

> ## Example

- 대체모델을 입증하기 위해 회귀 분석과 분류의 예제를 고려해봅니다.
- 먼저, 날씨와 날짜 정보가 주어진 자전거 대여일수를 예측하는 SVM을 학습시킵니다. 
- SVM은 해석이 잘 되지 않기 때문에, CART 의사결정 트리를 해석할 수 있는 모델로 하여 SVM의 동작과 근사하게 학습시킵니다.

![jpg](/assets/images/ML/5_5.png)

- SVM 에 대해 적합시킨 나무모형의 해석은 아래와 같았습니다.
  - 자전거 대여 데이터셋에서 학습된 SVM 시스템의 예측에 근접한 대체 트리의 말단 노드. 
  - 노드의 분포에 따르면 대체 트리는 온도가 섭씨 13도 이상일 때, 그리고 2년 중 낮일 때(435일을 기준으로 하였을 때) 대여 자전가수가 더 많을 것으로 나타났다.
-  대체 모델은 0.77의 R-제곱(설명되어진 분산)을 가비며, 이는 블랙박스 기본 동작에 상당히 가깝지만 완벽하지는 않다는 것을 의미합니다. 만약 완벽하게 맞출 수 있었다면 SVM을 포기하고 트리를 대신 쓸 수도 있었을 것입니다.

# [장점과 단점](#link){: .btn .btn--primary}{: .align-center}

> ## 장점

- 대체모델 방법은 **유연**합니다. 해석할 수 있는 모든 모델을 사용할 수 있습니다. 
  - 이는 해석할 수 있는 모델뿐만 아니라, 기본 블랙박스 모델로도 바꿀 수 있음을 의미합니다. 
  - 복잡한 모델을 만들어 회사의 여러 팀에게 설명한다고 가정해봅시다. 한 팀은 선형 모델에 익숙하고, 다른 팀은 의사결정 트리를 이해할 수 있습니다. 
  - 원본 블랙박스 모델에 대해 두 가지 대체모델(선형모델과 의사결정 트리)을 학습시키고 두 가지 종류의 설명을 제공할 수 있습니다. 
  - 성능이 더 좋은 블랙박스 모델을 찾으면 같은 종류의 대체 모델을 사용할 수 있기 때문에 해석 방법을 변경할 필요가 없습니다.
- 대체모델의 접근범은 매우 **직관적**이라고 할 수 있겠습니다. 
  - 이는 구현이 쉽지만 데이터 사이언스나 기계학습에 익숙하지 않은 사람들에게도 설명하기 쉽다는 것을 의미합니다.

- **R-제곱** 측정으로 블랙박스 예측에 근사치에서 대리모델이 얼마나 우수한지 쉽게 측정할 수 있습니다.

> ## 단점

- 대체모델은 실제 결과를 보지 못하기 때문에, 데이터**에 대해 결론을 도출하는 것이 아니라, 모델에 대해 결론을 내림**을 알고 있어야 합니다.
- 대체모델이 블랙박스 모델과 충분히 가깝다고 확신하기 위해서는 **R-제곱에 대한 최선의 컷오프**가 무엇인지 명확하지 않습니다. 80%의 셜명된 분산이 50%인지 99%인지에 대해서 말이지요.
- 대체모델이 블랙박스 모델과 얼마나 가까운지 측정할 수 있습니다. 
  - 매우 가깝지는 않지만, 충분히 가깝다고 가정하였을 때, 해석할 수 있는 모델이 **데이터셋의 한 부분집합에 대해 매우 가깝지만 다른 부분 집합에 대해서는 크게 다를 수 있습니다**. 
  - 이 경우 단순 모델에 대한 해석은 모든 데이터 포인트에 대해 동등하게 좋지 않을 것입니다.

- 여러분이 대리로서 선택한 해석할 수 있는 모델은 **그 모든 장단점이 함께 공존합니다.**

- 어떤 사람들은 일반적으로 **본질적으로 해석할 수 있는 모델**(선형 모델과 의사결정 트리까지 포함)**이 없으며**, 해석력에 대한 환상을 갖는 것조차 위험할 것이라고 주장합니다. 
  - 만약 여러분이 이 의견을 공유한다면, 물론 이 방법은 여러분을 위한 것은 아닐 것입니다. 

**Reference**

- https://christophm.github.io/interpretable-ml-book/global.html
- <https://eair.tistory.com/25?category=883307>

 전역 대체모델(Global surrogate model)은 블랙박스 모델의 예측에 근사하게 학습된 해석할 수 있는 모델입니다. 매우 직관적이며 특별한 이해가 필요하지 않은 장점이 있지만 , 역시 '모델의 예측값' 을 훈련한다는것 그 자체에서 오는 괴리감이 상당합니다...
{: .notice--warning}
