---
title: "Tensor Manipulation" 
excerpt: "Tensor 를 자유자재로 다루어보기"
categories:
  - Py_Pytorch
date : 2021-09-22 16:00:00 +0900
last_modified_at: 2021-09-22

toc: true
toc_label: "Table Of Contents"
toc_icon: "cog"
toc_sticky: true

use_math: true
---

 텐서의 연산에 대해서 알아봅시다.
{: .notice--warning}

# [Tensor Manipulation](#link){: .btn .btn--primary}{: .align-center}



> ## 행렬 곱셈과, 곱셈

- 메인 Namespace 입니다. 다양한 수학 함수가 포함되어 있으며 Numpy 와 유사한 행동을 합니다. 

> 행렬 곱셈

```python
m1 = torch.FloatTensor([[1, 2],
                        [3, 4]])
m2 = torch.FloatTensor([[1],
                        [2]])
print(m1.matmul(m2)) # m1@m2 도 같습니다.
#tensor([[ 5.],
#        [11.]])
```

- 위와 같이 m1 과 m2 를 행렬곱한 결과를 `m1@m2` 와 같은 형태로 나타낼 수 있습니다.

> 내적 곱

```python
m1 = torch.FloatTensor([[1, 2],
                        [3, 4]])
m2 = torch.FloatTensor([[1],
                        [2]])
print(m1 * m2) 
#tensor([[1., 2.],
#        [6., 8.]])

```

- 하지만 위와 같은 작업을 그냥 곱셈을 이용해서 하게된다면, 위와 같이 브로드캐스팅 된 이후의 곱셈으로 계산됩니다. 

> ## 평균 

```python
t = torch.FloatTensor([1, 2])
print(t.mean())
# tensor(1.5000)
```

- 위와 같이 1차원 Tensor 인 경우 mean 메서드를 실행하면 평균을 출력합니다.

```python
t = torch.FloatTensor([[1, 2], [3, 4]])
print(t.mean())
# tensor(2.5000)
```

- 위와 같이 2차원 이상의 경우에도 아무 인자없이 mean 을 그대로 실행하면 전체의 평균이 나오게 됩니다. 

```python
print(t.mean(dim=0))
# tensor([2., 3.])
print(t.mean(dim=1))
# tensor([1.5000, 3.5000])
```

- 위와 같이 mean 에 dim 인자를 주어서 '해당 차원의 입장에서' 평균을 보겠다는 의미가 됩니다.
  - dim = 0 이면 첫번쨰 차원(행) 을 제거하면서 mean 을 보게 됩니다. 즉 행이 제거된(행을 기준으로 평균).
  - dim = 2 이면 두번쨰 차원을 제거하면서 mean 을 보게 됩니다. 즉 열이 제거된 (열을 기준으로 평균)

```python
print(t.mean(dim=-1))
tensor([1.5000, 3.5000])
```

- 위는 마지막 차원을 제거하면서 평균을 본다는 의미입니다. 

> ## 최소, 최대 

- 최대나, 최나 결국엔
- 최대는 기본적으로 원소의 최댓값을 Return 합니다. 
- Argmax 는 최댓값을 가지는 인덱스를 Return 하게 됩니다. 

```python
t = torch.FloatTensor([[1, 2], [3, 4]])
print(t.max())
# tensor(4.)
```

- 위와 같이 max 메서드를 그냥 사용하게 된다면 

**Reference**

- <https://wikidocs.net/52460>

ing
{: .notice--success}

